{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a custom Environment for Financial Trading\n",
    "\n",
    "Some examples on the market\n",
    "* [custom env example](https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb#scrollTo=RqxatIwPOXe_)\n",
    "* [StockTradingEnv by Adam King](https://github.com/notadamking/Stock-Trading-Environment)\n",
    "* [FinRL](https://github.com/AI4Finance-Foundation/FinRL)\n",
    "\n",
    "Target is to construct a custom Env for pair trading\n",
    "\n",
    "This env gives the RL learner freedom to operate whatever it wants. Even long n short simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.read2df import read2df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT', 'XMRUSDT', 'BNBUSDT', 'ADAUSDT', 'DOGEUSDT', 'SOLUSDT', 'TRXUSDT']\n",
    "start_date = '2018-01-01'\n",
    "\n",
    "# freqs = {'1h':60, '2h':120, '4h':240, '6h':360, '8h':480, '12h':720, '1d':1440}\n",
    "freqs = {'1m':1, '3m':3, '5m':5, '15m':15, '30m':30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from `binance-public-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = read2df(symbols, freqs)\n",
    "dfs = read2df(symbols, freqs)\n",
    "\n",
    "df0 = dfs[0][dfs[0]['tic']=='BTCUSDT'].reset_index(drop=True)\n",
    "df1 = dfs[0][dfs[0]['tic']=='ETHUSDT'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_date = '2023-01-01'\n",
    "\n",
    "train0 = df0[df0['datetime'] < trade_date]\n",
    "train1 = df1[df1['datetime'] < trade_date]\n",
    "\n",
    "trade0 = df0[df0['datetime'] >= trade_date]\n",
    "trade1 = df1[df1['datetime'] >= trade_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass PairTradingActionSpace(gym.Space):\\n  def __init__(self, low=-1.0, high=1.0, shape=(2, ), dtype=np.float32):\\n    super().__init__(shape, dtype)\\n    self.low = low\\n    self.high = high\\n\\n  def sample(self):\\n    action = np.random.uniform(self.low, self.high, self.shape)\\n    # Normalize the action so that the summation of action[0] and action[1] is within -1 and 1.\\n    action = action / np.linalg.norm(action)\\n    return action\\n\\n  def contains(self, x):\\n    return np.all(self.low <= x) and np.all(x <= self.high) and np.linalg.norm(x) <= 1.0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't use custom observation & action spaces\n",
    "# See the warning on https://gymnasium.farama.org/api/spaces/\n",
    "\n",
    "'''\n",
    "class PairTradingActionSpace(gym.Space):\n",
    "  def __init__(self, low=-1.0, high=1.0, shape=(2, ), dtype=np.float32):\n",
    "    super().__init__(shape, dtype)\n",
    "    self.low = low\n",
    "    self.high = high\n",
    "\n",
    "  def sample(self):\n",
    "    action = np.random.uniform(self.low, self.high, self.shape)\n",
    "    # Normalize the action so that the summation of action[0] and action[1] is within -1 and 1.\n",
    "    action = action / np.linalg.norm(action)\n",
    "    return action\n",
    "\n",
    "  def contains(self, x):\n",
    "    return np.all(self.low <= x) and np.all(x <= self.high) and np.linalg.norm(x) <= 1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lookback period for the observation space\n",
    "PERIOD = 30\n",
    "CASH = 10000\n",
    "\n",
    "class PairTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    # for pair trading, we need to feed in two OHLCV dataframes\n",
    "    def __init__(self, df0, df1, tc=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        if not df0['time'].equals(df1['time']):\n",
    "            raise ValueError(\"Two dataframe must have same time index\")\n",
    "\n",
    "        self.tic0 = df0['tic'].iloc[0]\n",
    "        self.tic1 = df1['tic'].iloc[0]\n",
    "\n",
    "        # transaction cost\n",
    "        self.tc = tc\n",
    "\n",
    "        # get two datasets\n",
    "        self.df0 = df0[['time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        self.df1 = df1[['time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        # -1 means short 100%, 1 means long 100%, 0 means do nothing\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(2, ), dtype=np.float32)\n",
    "\n",
    "        # The data requires to be at least [time, open, high, low, close, volume]\n",
    "        # Let's assume that we feed in previous 30 period data into the observation_space\n",
    "        self.observation_space = spaces.Box(low=0.0, high=np.inf, shape=(2*PERIOD*6,), dtype=np.float64)\n",
    "\n",
    "        # if the length is 35, then the index shall be 0~34\n",
    "        self.max_steps = len(df0)-1\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # The current step is always higher than the PERIOD as defined in the \n",
    "\n",
    "        obs_df0 = self.df0.iloc[self.current_step-PERIOD: self.current_step]\n",
    "        obs_df1 = self.df1.iloc[self.current_step-PERIOD: self.current_step]\n",
    "\n",
    "        obs = np.array([obs_df0, obs_df1]).flatten()\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        self.action = action\n",
    "\n",
    "        current_price0 = self.df0['close'].iloc[self.current_step]\n",
    "        current_price1 = self.df1['close'].iloc[self.current_step]\n",
    "\n",
    "        # evaluate purchasing power \n",
    "        max_amount0 = self.net_worth/current_price0\n",
    "        max_amount1 = self.net_worth/current_price1\n",
    "\n",
    "        curr_holding0 = self.holding0/max_amount0\n",
    "        curr_holding1 = self.holding1/max_amount1\n",
    "\n",
    "        # clip the action to the summation of [-1, 1]\n",
    "        if sum(self.action) > 1:\n",
    "            action0 = self.action[0]/(sum(self.action)+self.tc)\n",
    "            action1 = self.action[1]/(sum(self.action)+self.tc)\n",
    "            self.action = [action0, action1]\n",
    "        elif sum(self.action) < -1:\n",
    "            action0 = self.action[0]/(sum(self.action)-self.tc)\n",
    "            action1 = self.action[1]/(sum(self.action)-self.tc)\n",
    "\n",
    "        # if curr_h is -70%, action is -40%, then we need to clip the action to -30%\n",
    "        if curr_holding0 + self.action[0] > 1:\n",
    "            self.action[0] = 1 - curr_holding0\n",
    "        elif curr_holding0 + self.action[0] < -1:\n",
    "            self.action[0] = -1 - curr_holding0\n",
    "\n",
    "        if curr_holding1 + self.action[1] > 1:\n",
    "            self.action[1] = 1 - curr_holding1\n",
    "        elif curr_holding0 + self.action[0] < -1:\n",
    "            self.action[1] = -1 - curr_holding1\n",
    "\n",
    "        self.holding0 += self.action[0]*max_amount0\n",
    "        self.holding1 += self.action[1]*max_amount1\n",
    "        self.cash -= self.cash*sum(action)*(1+self.tc)\n",
    "\n",
    "        # We record the net_worth from previous period to prev_net_worth\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.cash + self.holding0*current_price0 + self.holding1*current_price1\n",
    "\n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "\n",
    "        observation = self._next_observation()\n",
    "        reward = self.net_worth - self.prev_net_worth\n",
    "        terminated = bool(self.current_step >= self.max_steps)\n",
    "        truncated = bool(self.net_worth <= 0)\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.cash = CASH\n",
    "        self.net_worth = CASH\n",
    "        self.max_net_worth = CASH\n",
    "        self.holding0 = 0\n",
    "        self.holding1 = 0\n",
    "\n",
    "        self.current_step = np.random.randint(PERIOD, self.max_steps)\n",
    "\n",
    "        return self._next_observation(), {}\n",
    "    \n",
    "    def render(self):\n",
    "        profit = self.net_worth - CASH\n",
    "\n",
    "        print(f\"Current profit is {profit}, cash is {self.cash}, net worth is {self.net_worth}\")\n",
    "        print(f\"Actions for this step is {self.tic0} for {self.action[0]} and {self.tic1} for {self.action[1]}\")\n",
    "        print(f\"Current holding is {self.holding0} of {self.tic0} and {self.holding1} of {self.tic1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with baselin3 `env_checker`\n",
    "\n",
    "Check if the env meets the requirements of `stable_baseline3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a test run with random generated actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: Box(0.0, inf, (360,), float64)\n",
      "action_space: Box(-1.0, 1.0, (2,), float32)\n",
      "action_space.sample: [-0.5906395   0.37275356]\n",
      "Step 1\n",
      "Current profit is 0.8161022665972268, cash is 10816.91836886226, net worth is 10000.816102266597\n",
      "Actions for this step is BTCUSDT for -0.8730406171291096 and ETHUSDT for 0.7914303904695432\n",
      "Current holding is -0.1875142008291285 of BTCUSDT and 2.0178071925143177 of ETHUSDT\n",
      "Step 2\n",
      "Current profit is -67.55682499692921, cash is 9932.44317500307, net worth is 9932.44317500307\n",
      "Actions for this step is BTCUSDT for -0.12597763228256909 and ETHUSDT for 0.20766370701531855\n",
      "Current holding is -0.21454164991089947 of BTCUSDT and 2.5466550130038392 of ETHUSDT\n",
      "Step 3\n",
      "Current profit is -69.73613432453749, cash is 9930.263865675463, net worth is 9930.263865675463\n",
      "Actions for this step is BTCUSDT for 0.007790137182814849 and ETHUSDT for -0.007570943158036414\n",
      "Current holding is -0.21288326011071215 of BTCUSDT and 2.5275193079921907 of ETHUSDT\n",
      "Step 4\n",
      "Current profit is -68.6984175127509, cash is 9931.30158248725, net worth is 9931.30158248725\n",
      "Actions for this step is BTCUSDT for -0.0002845418969541491 and ETHUSDT for 0.00018014586622638884\n",
      "Current holding is -0.21294385155817924 of BTCUSDT and 2.527974712186516 of ETHUSDT\n",
      "Step 5\n",
      "Current profit is -66.78621445260796, cash is 12508.23992454477, net worth is 9933.213785547392\n",
      "Actions for this step is BTCUSDT for 0.0008530961957435856 and ETHUSDT for -0.260070275001294\n",
      "Current holding is -0.2127623448112233 of BTCUSDT and 1.871040261338082 of ETHUSDT\n",
      "Step 6\n",
      "Current profit is 1073.963476378176, cash is 18025.936482999507, net worth is 11073.963476378176\n",
      "Actions for this step is BTCUSDT for 0.5551246384242003 and ETHUSDT for -0.9958088919508825\n",
      "Current holding is -0.09450860878093639 of BTCUSDT and -0.6481775087334021 of ETHUSDT\n",
      "Step 7\n",
      "Current profit is -729.7902631886027, cash is 13364.641771345094, net worth is 9270.209736811397\n",
      "Actions for this step is BTCUSDT for 0.671917968111132 and ETHUSDT for -0.41358808450300066\n",
      "Current holding is 0.06498592982183307 of BTCUSDT and -1.8141447760397573 of ETHUSDT\n",
      "Step 8\n",
      "Current profit is -4096.558455529147, cash is 2414.451881749288, net worth is 5903.441544470853\n",
      "Actions for this step is BTCUSDT for 0.15867356420569223 and ETHUSDT for 0.6598482357883424\n",
      "Current holding is 0.09650382936466853 of BTCUSDT and -0.25814875949953686 of ETHUSDT\n",
      "Step 9\n",
      "Current profit is -5995.656405087124, cash is 3731.7869442784613, net worth is 4004.343594912876\n",
      "Actions for this step is BTCUSDT for 0.16749705684989902 and ETHUSDT for -0.7125561874266584\n",
      "Current holding is 0.11768480992676242 of BTCUSDT and -1.3281324293434333 of ETHUSDT\n",
      "Step 10\n",
      "Current profit is -6337.522247389959, cash is 8509.70027780017, net worth is 3662.4777526100406\n",
      "Actions for this step is BTCUSDT for -0.37088541293388055 and ETHUSDT for -0.9081640785293208\n",
      "Current holding is 0.08584584008002608 of BTCUSDT and -2.254291595171068 of ETHUSDT\n",
      "Step 11\n",
      "Current profit is -2542.513496414964, cash is 15163.629322950115, net worth is 7457.486503585036\n",
      "Actions for this step is BTCUSDT for -0.09259459469639242 and ETHUSDT for -0.6885471078765846\n",
      "Current holding is 0.07857062491132012 of BTCUSDT and -2.896877152402667 of ETHUSDT\n",
      "Step 12\n",
      "Current profit is -7451.585990357852, cash is 5516.811245720159, net worth is 2548.414009642148\n",
      "Actions for this step is BTCUSDT for -0.004132326541113951 and ETHUSDT for 0.6396781243896392\n",
      "Current holding is 0.07790981432761947 of BTCUSDT and -1.6816890609642454 of ETHUSDT\n",
      "Step 13\n",
      "Current profit is -4347.324878208493, cash is 11283.949779846214, net worth is 5652.675121791507\n",
      "Actions for this step is BTCUSDT for -0.4255910449026157 and ETHUSDT for -0.6187399826341082\n",
      "Current holding is 0.05465088645596929 of BTCUSDT and -2.083285876336959 of ETHUSDT\n",
      "Step 14\n",
      "Current profit is -1935.266587397051, cash is 16117.88059022749, net worth is 8064.733412602949\n",
      "Actions for this step is BTCUSDT for 0.39041545016649604 and ETHUSDT for -0.8183774495452649\n",
      "Current holding is 0.10197070376118861 of BTCUSDT and -3.261037986728345 of ETHUSDT\n",
      "Step 15\n",
      "Current profit is 6996.8513303375, cash is 33994.13292928019, net worth is 16996.8513303375\n",
      "Actions for this step is BTCUSDT for -0.9469223023847535 and ETHUSDT for -0.16106418784494836\n",
      "Current holding is -0.0616213696058307 of BTCUSDT and -3.591404850154328 of ETHUSDT\n",
      "Step 16\n",
      "Current profit is 23068.323136447063, cash is 66139.91087039025, net worth is 33068.32313644706\n",
      "Actions for this step is BTCUSDT for -0.8305728517770323 and ETHUSDT for -0.11410970105174534\n",
      "Current holding is -0.3637042248078002 of BTCUSDT and -4.084184205090561 of ETHUSDT\n",
      "Step 17\n",
      "Current profit is -34187.97225214636, cash is -24128.32299648774, net worth is -24187.972252146363\n",
      "Actions for this step is BTCUSDT for 0.49802934798930776 and ETHUSDT for 0.5012377526774855\n",
      "Current holding is -0.011572900447176238 of BTCUSDT and 0.12222217940599833 of ETHUSDT\n",
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(f\"observation_space: {env.observation_space}\")\n",
    "print(f\"action_space: {env.action_space}\")\n",
    "print(f\"action_space.sample: {env.action_space.sample()}\")\n",
    "\n",
    "n_steps = 100\n",
    "\n",
    "for step in range(n_steps):\n",
    "    print(f\"Step {step + 1}\")\n",
    "    obs, reward, terminated, truncated, info = env.step(action=[random.uniform(-1, 1) for _ in range(2)])\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Test Finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO model from stable_baselines3\n",
    "\n",
    "Train with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.78     |\n",
      "|    ep_rew_mean     | -3.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 2989     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.69          |\n",
      "|    ep_rew_mean          | -7.85e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2170          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015644016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.27e+09      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000347     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.03e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.55          |\n",
      "|    ep_rew_mean          | -3.5e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2035          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018730664 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.08e+10      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000443     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 9.8e+10       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.19          |\n",
      "|    ep_rew_mean          | -4.81e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1959          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0365674e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.4e+10       |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -8.02e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.47e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.55          |\n",
      "|    ep_rew_mean          | -4.81e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1889          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0586536e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.74e+10      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000123     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.29e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.09          |\n",
      "|    ep_rew_mean          | -6.04e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1883          |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8480263e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.35e+09      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -5.13e-05     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 1.68e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.14          |\n",
      "|    ep_rew_mean          | -3.23e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1881          |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9552007e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.37e+11      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00024      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 8.03e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.98          |\n",
      "|    ep_rew_mean          | -2.71e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1872          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9113882e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+12      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.000129     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 3.24e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.45         |\n",
      "|    ep_rew_mean          | -2.64e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1869         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.581717e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.12e+12     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000499    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 1.18e+13     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.47          |\n",
      "|    ep_rew_mean          | -8.92e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1852          |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3844332e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.89e+12      |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000186     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 5.35e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.49         |\n",
      "|    ep_rew_mean          | -6.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1844         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061795656 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+09      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0008      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.69e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.71         |\n",
      "|    ep_rew_mean          | -8.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1804         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003952801 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.55e+11     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.00137      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 4.56e+11     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.85         |\n",
      "|    ep_rew_mean          | -2.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1800         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.001939e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.6e+11      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000124    |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.84e+11     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.72         |\n",
      "|    ep_rew_mean          | -5.12e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1802         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.805044e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+11     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 3.34e-05     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.79e+13     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.71          |\n",
      "|    ep_rew_mean          | -3.74e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1803          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7997182e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.91e+09      |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000502     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 2.54e+13      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.78          |\n",
      "|    ep_rew_mean          | -4.34e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1805          |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7645008e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.78e+09      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 2.36e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.48         |\n",
      "|    ep_rew_mean          | -5.96e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1807         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.432688e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.8e+10      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 2.11e-05     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.94e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.46          |\n",
      "|    ep_rew_mean          | -6.87e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1810          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8274734e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+09      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000234     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 3.33e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.36          |\n",
      "|    ep_rew_mean          | -3.21e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1812          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2144536e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.14e+10      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000262     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 1.32e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.72          |\n",
      "|    ep_rew_mean          | -8.59e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1814          |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020745321 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.75e+09      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.00049      |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 2.37e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.53          |\n",
      "|    ep_rew_mean          | -6.98e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1811          |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 23            |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4715295e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.97e+10      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000348     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 7.71e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04          |\n",
      "|    ep_rew_mean          | -3.6e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1813          |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7643284e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.21e+09      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -8.46e-05     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 2.51e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.29          |\n",
      "|    ep_rew_mean          | -5.84e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1813          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018211873 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.01e+11      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000629     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 6e+11         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.19          |\n",
      "|    ep_rew_mean          | -1.75e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1815          |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019063358 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.17e+10      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000662     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 5.7e+10       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.84          |\n",
      "|    ep_rew_mean          | -3.04e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1815          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4087617e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.18e+10      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.000388     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 1.56e+13      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.19         |\n",
      "|    ep_rew_mean          | -6.03e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003197695 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.41e+09     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000696    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 5.38e+10     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.92         |\n",
      "|    ep_rew_mean          | -2.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003330299 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+10     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000809    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 7.7e+10      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.44          |\n",
      "|    ep_rew_mean          | -3.8e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1816          |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012309715 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.09e+08      |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.000195     |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 4.2e+09       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.74          |\n",
      "|    ep_rew_mean          | -3.39e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1815          |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032308654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.91e+10      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.000525     |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 3.28e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.69         |\n",
      "|    ep_rew_mean          | -3.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009786279 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+10     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 1.83e+10     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.19          |\n",
      "|    ep_rew_mean          | -3.21e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1817          |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057562627 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.75e+09      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    std                  | 0.995         |\n",
      "|    value_loss           | 7.88e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.72         |\n",
      "|    ep_rew_mean          | -3.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005643344 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+10     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 2.94e+10     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.5           |\n",
      "|    ep_rew_mean          | -1.52e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1816          |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 37            |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5227724e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.62e+10      |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | 4.59e-05      |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 5.98e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.75         |\n",
      "|    ep_rew_mean          | -4.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017423454 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+09     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 1.21e+11     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.85         |\n",
      "|    ep_rew_mean          | -2.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015106313 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49e+09     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 2.01e+10     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.27         |\n",
      "|    ep_rew_mean          | -4.71e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011893928 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.87e+09     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 4.07e+09     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.89          |\n",
      "|    ep_rew_mean          | -2.56e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1817          |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 41            |\n",
      "|    total_timesteps      | 75776         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079562445 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.25e+10      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.000865     |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 1.01e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.57         |\n",
      "|    ep_rew_mean          | -2.34e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1817         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011852458 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+10     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000737    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 1.07e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.69          |\n",
      "|    ep_rew_mean          | -2.92e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1818          |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 43            |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023934635 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.9e+09       |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000198     |\n",
      "|    std                  | 0.991         |\n",
      "|    value_loss           | 2.79e+12      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.59        |\n",
      "|    ep_rew_mean          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001035053 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+09    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 3.22e+10    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.4          |\n",
      "|    ep_rew_mean          | -5.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1819         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.798312e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+11     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000229    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 7.85e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.3           |\n",
      "|    ep_rew_mean          | -5.08e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1818          |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 47            |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0374009e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.78e+11      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    std                  | 0.99          |\n",
      "|    value_loss           | 1.97e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.2           |\n",
      "|    ep_rew_mean          | -4.9e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1817          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9572125e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.82         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.54e+09      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000164     |\n",
      "|    std                  | 0.99          |\n",
      "|    value_loss           | 1.67e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.4          |\n",
      "|    ep_rew_mean          | -6.44e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1815         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066806953 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96e+11     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 4.49e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.55          |\n",
      "|    ep_rew_mean          | -1.09e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1815          |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018609586 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.81         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.02e+11      |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | 0.000489      |\n",
      "|    std                  | 0.986         |\n",
      "|    value_loss           | 4.71e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.03         |\n",
      "|    ep_rew_mean          | -9.13e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1815         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.121692e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8e+14        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -7.13e-05    |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 1.8e+16      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.14         |\n",
      "|    ep_rew_mean          | -9.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1816         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.902823e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+15      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000112    |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 2.19e+16     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.21          |\n",
      "|    ep_rew_mean          | -4.26e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1816          |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 54            |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095180323 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.81         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.82e+10      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000977     |\n",
      "|    std                  | 0.985         |\n",
      "|    value_loss           | 1.09e+13      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.05        |\n",
      "|    ep_rew_mean          | -3.56e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1818        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022800043 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+12    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 4.7e+12     |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "model.save(\"ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on Trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = PPO.load(\"ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current profit is -2071.056590032498, cash is -2062.7652072906476, net worth is 7928.943409967502\n",
      "Actions for this step is BTCUSDT for 0.17003258754051856 and ETHUSDT for 0.8291382741852962\n",
      "Current holding is 0.0595668802747814 of BTCUSDT and 4.488014691522348 of ETHUSDT\n",
      "Current profit is 2401.290374679047, cash is -1138.599144590546, net worth is 12401.290374679047\n",
      "Actions for this step is BTCUSDT for 0.7855759263038635 and ETHUSDT for -0.3380005955696106\n",
      "Current holding is 0.27779943618792036 of BTCUSDT and 3.0372946900030073 of ETHUSDT\n",
      "Current profit is 12649.202002792757, cash is 519.9178915542943, net worth is 22649.202002792757\n",
      "Actions for this step is BTCUSDT for 0.3606212961901629 and ETHUSDT for 0.3318531481411479\n",
      "Current holding is 0.4344834048000182 of BTCUSDT and 5.264379230668176 of ETHUSDT\n",
      "Current profit is 23336.351444272805, cash is 268.5045000361299, net worth is 33336.351444272805\n",
      "Actions for this step is BTCUSDT for -0.08750295639038086 and ETHUSDT for 0.5705835223197937\n",
      "Current holding is 0.365043513418888 of BTCUSDT and 12.259378665843286 of ETHUSDT\n",
      "Current profit is 43950.42723782212, cash is -120.9028235793237, net worth is 53950.42723782212\n",
      "Actions for this step is BTCUSDT for 0.30957587628714517 and ETHUSDT for 0.32089436227264356\n",
      "Current holding is 0.7267671260870809 of BTCUSDT and 18.052241042895176 of ETHUSDT\n",
      "Current profit is 87860.85736319426, cash is 90.73888607478557, net worth is 97860.85736319426\n",
      "Actions for this step is BTCUSDT for 0.42792224016289326 and ETHUSDT for 0.3822066777081615\n",
      "Current holding is 1.5360320262234044 of BTCUSDT and 29.220518240512 of ETHUSDT\n",
      "Current profit is 47988.978903823874, cash is 127.80094281147817, net worth is 57988.978903823874\n",
      "Actions for this step is BTCUSDT for -0.8566046357154846 and ETHUSDT for 0.4485653340816498\n",
      "Current holding is -1.401849225413847 of BTCUSDT and 52.98999168977932 of ETHUSDT\n",
      "Current profit is 29481.059223365068, cash is -75.95259385414059, net worth is 39481.05922336507\n",
      "Actions for this step is BTCUSDT for 0.3719062581734967 and ETHUSDT for -0.6871473408597133\n",
      "Current holding is -0.6459963048119893 of BTCUSDT and 31.408040309495085 of ETHUSDT\n",
      "Current profit is 17017.416650153584, cash is 13.565904075503099, net worth is 27017.416650153584\n",
      "Actions for this step is BTCUSDT for 0.15056669209863804 and ETHUSDT for -0.46835808822858405\n",
      "Current holding is -0.4375390244584677 of BTCUSDT and 21.389905201792775 of ETHUSDT\n",
      "Current profit is -9972.864372073145, cash is 27.136012540645467, net worth is 27.135627926854795\n",
      "Actions for this step is BTCUSDT for -0.5383797287940979 and ETHUSDT for -0.46093088388442993\n",
      "Current holding is -0.9478332053156978 of BTCUSDT and 14.641284802381731 of ETHUSDT\n",
      "Current profit is -10007.818170510887, cash is -7.818170510888436, net worth is -7.818170510886375\n",
      "Actions for this step is BTCUSDT for 994.7460369712617 and ETHUSDT for -994.7461957369661\n",
      "Current holding is -0.0009518824781855617 of BTCUSDT and 0.014703832025736219 of ETHUSDT\n",
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(trade0, trade1)\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Test Finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoa-mdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
