{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a custom Environment for Financial Trading\n",
    "\n",
    "Some examples on the market\n",
    "* [custom env example](https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb#scrollTo=RqxatIwPOXe_)\n",
    "* [StockTradingEnv by Adam King](https://github.com/notadamking/Stock-Trading-Environment)\n",
    "* [FinRL](https://github.com/AI4Finance-Foundation/FinRL)\n",
    "\n",
    "Target is to construct a custom Env for pair trading\n",
    "\n",
    "This env gives the RL learner freedom to operate whatever it wants. Even long n short simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.read2df import read2df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT', 'XMRUSDT', 'BNBUSDT', 'ADAUSDT', 'DOGEUSDT', 'SOLUSDT', 'TRXUSDT']\n",
    "start_date = '2018-01-01'\n",
    "\n",
    "# freqs = {'1h':60, '2h':120, '4h':240, '6h':360, '8h':480, '12h':720, '1d':1440}\n",
    "freqs = {'1m':1, '3m':3, '5m':5, '15m':15, '30m':30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from `binance-public-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = read2df(symbols, freqs)\n",
    "dfs = read2df(symbols, freqs)\n",
    "\n",
    "df0 = dfs[0][dfs[0]['tic']=='BTCUSDT'].reset_index(drop=True)\n",
    "df1 = dfs[0][dfs[0]['tic']=='ETHUSDT'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_date = '2023-01-01'\n",
    "\n",
    "train0 = df0[df0['datetime'] < trade_date]\n",
    "train1 = df1[df1['datetime'] < trade_date]\n",
    "\n",
    "trade0 = df0[df0['datetime'] >= trade_date]\n",
    "trade1 = df1[df1['datetime'] >= trade_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass PairTradingActionSpace(gym.Space):\\n  def __init__(self, low=-1.0, high=1.0, shape=(2, ), dtype=np.float32):\\n    super().__init__(shape, dtype)\\n    self.low = low\\n    self.high = high\\n\\n  def sample(self):\\n    action = np.random.uniform(self.low, self.high, self.shape)\\n    # Normalize the action so that the summation of action[0] and action[1] is within -1 and 1.\\n    action = action / np.linalg.norm(action)\\n    return action\\n\\n  def contains(self, x):\\n    return np.all(self.low <= x) and np.all(x <= self.high) and np.linalg.norm(x) <= 1.0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't use custom observation & action spaces\n",
    "# See the warning on https://gymnasium.farama.org/api/spaces/\n",
    "\n",
    "'''\n",
    "class PairTradingActionSpace(gym.Space):\n",
    "  def __init__(self, low=-1.0, high=1.0, shape=(2, ), dtype=np.float32):\n",
    "    super().__init__(shape, dtype)\n",
    "    self.low = low\n",
    "    self.high = high\n",
    "\n",
    "  def sample(self):\n",
    "    action = np.random.uniform(self.low, self.high, self.shape)\n",
    "    # Normalize the action so that the summation of action[0] and action[1] is within -1 and 1.\n",
    "    action = action / np.linalg.norm(action)\n",
    "    return action\n",
    "\n",
    "  def contains(self, x):\n",
    "    return np.all(self.low <= x) and np.all(x <= self.high) and np.linalg.norm(x) <= 1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom Environment\n",
    "\n",
    "The RL learner can do whatever they want. \n",
    "\n",
    "We want to see if it can learn to be market-neutral itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lookback period for the observation space\n",
    "PERIOD = 1440\n",
    "CASH = 10000\n",
    "\n",
    "class PairTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    # for pair trading, we need to feed in two OHLCV dataframes\n",
    "    def __init__(self, df0, df1, tc=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        if not df0['time'].equals(df1['time']):\n",
    "            raise ValueError(\"Two dataframe must have same time index\")\n",
    "\n",
    "        self.tic0 = df0['tic'].iloc[0]\n",
    "        self.tic1 = df1['tic'].iloc[0]\n",
    "\n",
    "        # transaction cost\n",
    "        self.tc = tc\n",
    "\n",
    "        # get two datasets\n",
    "        self.df0 = df0[['time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        self.df1 = df1[['time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        # -1 means short 100%, 1 means long 100%, 0 means do nothing\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(2, ), dtype=np.float32)\n",
    "\n",
    "        # The data requires to be at least [time, open, high, low, close, volume]\n",
    "        # Let's assume that we feed in previous 30 period data into the observation_space\n",
    "        self.observation_space = spaces.Box(low=0.0, high=np.inf, shape=(2*PERIOD*6,), dtype=np.float64)\n",
    "\n",
    "        # if the length is 35, then the index shall be 0~34\n",
    "        self.max_steps = len(df0)-1\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # The current step is always higher than the PERIOD as defined in the \n",
    "\n",
    "        obs_df0 = self.df0.iloc[self.current_step-PERIOD: self.current_step]\n",
    "        obs_df1 = self.df1.iloc[self.current_step-PERIOD: self.current_step]\n",
    "\n",
    "        obs = np.array([obs_df0, obs_df1]).flatten()\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        self.action = action\n",
    "\n",
    "        current_price0 = self.df0['close'].iloc[self.current_step]\n",
    "        current_price1 = self.df1['close'].iloc[self.current_step]\n",
    "\n",
    "        # evaluate purchasing power \n",
    "        max_amount0 = self.net_worth/current_price0\n",
    "        max_amount1 = self.net_worth/current_price1\n",
    "\n",
    "        curr_holding0 = self.holding0/max_amount0\n",
    "        curr_holding1 = self.holding1/max_amount1\n",
    "\n",
    "        # clip the action to the summation of [-1, 1]\n",
    "        if sum(self.action) > 1:\n",
    "            action0 = self.action[0]/(sum(self.action)+self.tc)\n",
    "            action1 = self.action[1]/(sum(self.action)+self.tc)\n",
    "            self.action = [action0, action1]\n",
    "        elif sum(self.action) < -1:\n",
    "            action0 = self.action[0]/(sum(self.action)-self.tc)\n",
    "            action1 = self.action[1]/(sum(self.action)-self.tc)\n",
    "\n",
    "        # if curr_h is -70%, action is -40%, then we need to clip the action to -30%\n",
    "        if curr_holding0 + self.action[0] > 1:\n",
    "            self.action[0] = 1 - curr_holding0\n",
    "        elif curr_holding0 + self.action[0] < -1:\n",
    "            self.action[0] = -1 - curr_holding0\n",
    "\n",
    "        if curr_holding1 + self.action[1] > 1:\n",
    "            self.action[1] = 1 - curr_holding1\n",
    "        elif curr_holding0 + self.action[0] < -1:\n",
    "            self.action[1] = -1 - curr_holding1\n",
    "\n",
    "        self.holding0 += self.action[0]*max_amount0\n",
    "        self.holding1 += self.action[1]*max_amount1\n",
    "        self.cash -= self.cash*sum(action)*(1+self.tc)\n",
    "\n",
    "        # We record the net_worth from previous period to prev_net_worth\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.cash + self.holding0*current_price0 + self.holding1*current_price1\n",
    "\n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "\n",
    "        observation = self._next_observation()\n",
    "\n",
    "        # TODO: what if I heavily punish loss?\n",
    "        reward = self.net_worth - self.prev_net_worth\n",
    "        \n",
    "        terminated = bool(self.current_step >= self.max_steps)\n",
    "        truncated = bool(self.net_worth <= 0)\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.cash = CASH\n",
    "        self.net_worth = CASH\n",
    "        self.max_net_worth = CASH\n",
    "        self.holding0 = 0\n",
    "        self.holding1 = 0\n",
    "\n",
    "        self.current_step = np.random.randint(PERIOD, self.max_steps)\n",
    "\n",
    "        return self._next_observation(), {}\n",
    "    \n",
    "    def render(self):\n",
    "        profit = self.net_worth - CASH\n",
    "\n",
    "        print(\"----------------------------------------\")\n",
    "        print(f\"Current profit is {profit}, cash is {self.cash}, net worth is {self.net_worth}\")\n",
    "        print(f\"Actions for this step is {self.tic0} for {self.action[0]} and {self.tic1} for {self.action[1]}\")\n",
    "        print(f\"Current holding is {self.holding0} of {self.tic0} and {self.holding1} of {self.tic1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with baselin3 `env_checker`\n",
    "\n",
    "Check if the env meets the requirements of `stable_baseline3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a test run with random generated actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: Box(0.0, inf, (12000,), float64)\n",
      "action_space: Box(-1.0, 1.0, (2,), float32)\n",
      "action_space.sample: [-0.33985785  0.5390888 ]\n",
      "Step 1\n",
      "Current profit is 10.120015260687069, cash is 20130.135275947374, net worth is 10010.120015260687\n",
      "Actions for this step is BTCUSDT for -0.8602067228949191 and ETHUSDT for -0.15179480317374971\n",
      "Current holding is -0.14137480298895078 of BTCUSDT and -0.37027638290950043 of ETHUSDT\n",
      "Step 2\n",
      "Current profit is 5460.813735583637, cash is 30965.816456415538, net worth is 15460.813735583637\n",
      "Actions for this step is BTCUSDT for -0.14053751362783418 and ETHUSDT for -0.39720633040277065\n",
      "Current holding is -0.16449211598018768 of BTCUSDT and -1.3396271650424723 of ETHUSDT\n",
      "Step 3\n",
      "Current profit is -1231.8525107725673, cash is 17619.996029542835, net worth is 8768.147489227433\n",
      "Actions for this step is BTCUSDT for 0.0667777112417074 and ETHUSDT for 0.3637773157087132\n",
      "Current holding is -0.14752822364214097 of BTCUSDT and 0.030911522974716554 of ETHUSDT\n",
      "Step 4\n",
      "Current profit is -20722.977138106344, cash is -10644.13034769832, net worth is -10722.977138106344\n",
      "Actions for this step is BTCUSDT for 0.6018566968811897 and ETHUSDT for 0.397519663941644\n",
      "Current holding is -0.060718900226060066 of BTCUSDT and 0.8808516684817792 of ETHUSDT\n",
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(f\"observation_space: {env.observation_space}\")\n",
    "print(f\"action_space: {env.action_space}\")\n",
    "print(f\"action_space.sample: {env.action_space.sample()}\")\n",
    "\n",
    "n_steps = 100\n",
    "\n",
    "for step in range(n_steps):\n",
    "    print(f\"Step {step + 1}\")\n",
    "    obs, reward, terminated, truncated, info = env.step(action=[random.uniform(-1, 1) for _ in range(2)])\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Test Finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO model from stable_baselines3\n",
    "\n",
    "Train with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.86     |\n",
      "|    ep_rew_mean     | -5.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.33          |\n",
      "|    ep_rew_mean          | -1.57e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 693           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019665368 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.68e+09      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00036      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 1.88e+10      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 4.78          |\n",
      "|    ep_rew_mean          | -3.3e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 607           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4370478e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.04e+11      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000299     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 1.44e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.52          |\n",
      "|    ep_rew_mean          | -6.63e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 570           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4300763e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.47e+09      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -6.49e-05     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 5.28e+10      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.4          |\n",
      "|    ep_rew_mean          | -4.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003950531 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+10     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000895    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 4.76e+10     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.3          |\n",
      "|    ep_rew_mean          | -3.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001006604 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+10     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 8.75e+10     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.18         |\n",
      "|    ep_rew_mean          | -2.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.725781e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+10     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000296    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 8.37e+10     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.36          |\n",
      "|    ep_rew_mean          | -8.02e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 479           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 34            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021338472 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.51e+11      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00069      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 2.16e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.88         |\n",
      "|    ep_rew_mean          | -3.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.794683e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.41e+10     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -8.49e-05    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 1.93e+12     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.24        |\n",
      "|    ep_rew_mean          | -5.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 455         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006595655 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.63e+10    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.000696   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.95e+11    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.58        |\n",
      "|    ep_rew_mean          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 1.33875e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.97e+10    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.000102   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.5e+13     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.53         |\n",
      "|    ep_rew_mean          | -7.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060042506 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+11     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -2e-05       |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.58e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.16         |\n",
      "|    ep_rew_mean          | -1.17e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014307925 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+12     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000323    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 2.38e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.88         |\n",
      "|    ep_rew_mean          | -6.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.441108e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+10     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 2.57e-06     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 5.21e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.79         |\n",
      "|    ep_rew_mean          | -6.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.206605e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.12e+11     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.00017      |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 3.32e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.98         |\n",
      "|    ep_rew_mean          | -2.58e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016587506 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81e+11     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000855    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 2.82e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.76          |\n",
      "|    ep_rew_mean          | -4.7e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0486954e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.76e+11      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -3.47e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 3.63e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.64          |\n",
      "|    ep_rew_mean          | -1.72e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 426           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 86            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9205938e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9e+14         |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 1.69e-05      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.36e+14      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.11          |\n",
      "|    ep_rew_mean          | -3.47e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 90            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6775117e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.65e+10      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000158     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 4.65e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.45         |\n",
      "|    ep_rew_mean          | -1.16e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.680887e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+11     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000123    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 3.59e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.68          |\n",
      "|    ep_rew_mean          | -4.77e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 432           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 99            |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3648329e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.39e+14      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000102     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 3.48e+14      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.48          |\n",
      "|    ep_rew_mean          | -1.81e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 424           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 106           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3582252e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.19e+11      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -2.93e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.09e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.58          |\n",
      "|    ep_rew_mean          | -9.17e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 406           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 115           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4839857e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.49e+11      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000186     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.18e+12      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.3           |\n",
      "|    ep_rew_mean          | -1.94e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 399           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1604268e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.52e+10      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000202     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.97e+13      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.54          |\n",
      "|    ep_rew_mean          | -8.97e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 402           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2105904e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.61e+12      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -5.08e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 2.3e+12       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.46         |\n",
      "|    ep_rew_mean          | -6.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.403803e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+13     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -6.98e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 2.68e+13     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.82         |\n",
      "|    ep_rew_mean          | -9.7e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.025709e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+13     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -6.79e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 1.45e+13     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.17         |\n",
      "|    ep_rew_mean          | -1.13e+07    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027848324 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+11     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000558    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 8.65e+13     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.88          |\n",
      "|    ep_rew_mean          | -1.25e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 408           |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8480932e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.08e+14      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | 7.1e-06       |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 5.33e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.24          |\n",
      "|    ep_rew_mean          | -1.08e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 410           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.2538956e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.55e+12      |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -5.97e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 8.19e+14      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.82         |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 412          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002691238 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+13      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000394    |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 1.08e+13     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.69          |\n",
      "|    ep_rew_mean          | -6.21e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 414           |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 158           |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1031621e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.09e+10      |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.000112     |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 3.9e+11       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.24          |\n",
      "|    ep_rew_mean          | -2.38e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 412           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 163           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6397389e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5e+13         |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -3.89e-05     |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 3.2e+13       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.48          |\n",
      "|    ep_rew_mean          | -3.84e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 411           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 169           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028398834 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.29e+14      |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 3.71e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 7.24          |\n",
      "|    ep_rew_mean          | -1.21e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 412           |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 173           |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0538235e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.3e+11       |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -7.41e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.71e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 7.14          |\n",
      "|    ep_rew_mean          | -2.27e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 413           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3424724e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.57e+10      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -9.5e-06      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 3.54e+12      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.3          |\n",
      "|    ep_rew_mean          | -2.49e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 414          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.266338e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.81e+11     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -3.33e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 1.75e+17     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.97          |\n",
      "|    ep_rew_mean          | -4.39e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 416           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 187           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2590105e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.95e+13      |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000104     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 5.59e+14      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.12         |\n",
      "|    ep_rew_mean          | -3.32e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.628935e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.35e+12     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -6.9e-05     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 3.97e+12     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.76          |\n",
      "|    ep_rew_mean          | -5.51e+06     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 195           |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3857715e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.8e+13       |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -8.13e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 3.87e+14      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.47          |\n",
      "|    ep_rew_mean          | -1.89e+06     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 200           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4979894e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.62e+11      |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -5.71e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.77e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.43          |\n",
      "|    ep_rew_mean          | -1.75e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 204           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1577884e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.68e+14      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | 3.16e-06      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 5.66e+13      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.47          |\n",
      "|    ep_rew_mean          | -3.3e+06      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 209           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1227181e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.91e+12      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -7.44e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.38e+14      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.9          |\n",
      "|    ep_rew_mean          | -5.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.526557e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.76e+13     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -2.25e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 5.71e+14     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.22         |\n",
      "|    ep_rew_mean          | -7.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 422          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.223911e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.85e+10     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -1.84e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 1.43e+13     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.23          |\n",
      "|    ep_rew_mean          | -4.97e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 222           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0867903e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.19e+13      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -5.23e-05     |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 1.55e+14      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.38         |\n",
      "|    ep_rew_mean          | -5e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003558922 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+11     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000104    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 2.49e+12     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.71         |\n",
      "|    ep_rew_mean          | -7.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 426          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.848698e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.11e+16     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -1.63e-05    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 3.59e+16     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 6.32          |\n",
      "|    ep_rew_mean          | -7.6e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 427           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 234           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1770346e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.49e+10      |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -4.11e-05     |\n",
      "|    std                  | 0.995         |\n",
      "|    value_loss           | 1.43e+11      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "model.save(\"ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation from AI\n",
    "\n",
    "---\n",
    "\n",
    "The text you've provided appears to be a summary of metrics and statistics related to some kind of training or optimization process. These values are often generated during the training of machine learning models, particularly reinforcement learning models like PPO (Proximal Policy Optimization) or other similar algorithms. Let's break down what each section means:\n",
    "\n",
    "1. **Rollout**:\n",
    "   - `ep_len_mean`: This is the mean (average) length of episodes. In a reinforcement learning context, episodes are sequences of actions taken by an agent in an environment until a termination condition is met.\n",
    "\n",
    "   - `ep_rew_mean`: This is the mean (average) reward obtained in episodes. It seems to be very negative, which might indicate that the agent is not performing well or that the environment is very challenging.\n",
    "\n",
    "2. **Time**:\n",
    "   - `fps`: Frames per second. This tells you how fast the training is progressing in terms of processing frames or steps in the environment per second.\n",
    "\n",
    "   - `iterations`: The number of training iterations that have been completed.\n",
    "\n",
    "   - `time_elapsed`: The total time (in some unit, possibly seconds) that has elapsed during the training.\n",
    "\n",
    "   - `total_timesteps`: The total number of timesteps or steps the agent has taken in the environment.\n",
    "\n",
    "3. **Train**:\n",
    "   - `approx_kl`: A measure of how much the current policy differs from the previous policy. It's used to control the rate of policy updates.\n",
    "\n",
    "   - `clip_fraction`: The fraction of actions that were clipped during training. Clipping means that the policy update is bounded within a certain range to ensure stability.\n",
    "\n",
    "   - `clip_range`: The range within which the policy update is clipped.\n",
    "\n",
    "   - `entropy_loss`: A measure of the entropy of the policy distribution. It's often used to encourage exploration.\n",
    "\n",
    "   - `explained_variance`: A measure of how well the value function (used to estimate expected rewards) explains the actual rewards. A value of 0 means no explanation, and 1 means perfect explanation.\n",
    "\n",
    "   - `learning_rate`: The learning rate used in the optimization process.\n",
    "\n",
    "   - `loss`: The overall loss of the model. In this case, it's a very large number, which might indicate a problem with the training process.\n",
    "\n",
    "   - `n_updates`: The number of updates performed on the policy.\n",
    "\n",
    "   - `policy_gradient_loss`: A loss term related to the policy gradient method used in reinforcement learning.\n",
    "\n",
    "   - `std`: The standard deviation of the policy distribution.\n",
    "\n",
    "   - `value_loss`: A loss term related to the value function, which estimates expected rewards.\n",
    "\n",
    "These values are crucial for monitoring and understanding the progress of a reinforcement learning training process. To assess whether the training is successful or not, you would typically look at metrics like `ep_rew_mean` (average reward), `approx_kl` (policy stability), and `explained_variance` (how well the model explains rewards). The large values for `loss` and `value_loss` could be indicative of problems in the training process, but further analysis would be needed to diagnose the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on Trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = PPO.load(\"ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Current profit is 2.0548489689826965, cash is 12056.90381795168, net worth is 10002.054848968983\n",
      "Actions for this step is BTCUSDT for -0.5627274513244629 and ETHUSDT for 0.35724255442619324\n",
      "Current holding is -0.20555120112989672 of BTCUSDT and 2.0794700336225924 of ETHUSDT\n",
      "----------------------------------------\n",
      "Current profit is 2210.7607164796937, cash is 24958.493052998507, net worth is 12210.760716479694\n",
      "Actions for this step is BTCUSDT for -0.06898924708366394 and ETHUSDT for -1.0\n",
      "Current holding is -0.23075251800940827 of BTCUSDT and -3.742447806289505 of ETHUSDT\n",
      "----------------------------------------\n",
      "Current profit is 14430.445797355507, cash is 48851.96714034401, net worth is 24430.445797355507\n",
      "Actions for this step is BTCUSDT for -0.48280754685401917 and ETHUSDT for -0.473564475774765\n",
      "Current holding is -0.4461637350121562 of BTCUSDT and -7.109033643549234 of ETHUSDT\n",
      "----------------------------------------\n",
      "Current profit is 2199.736970364331, cash is 24410.497020427007, net worth is 12199.73697036433\n",
      "Actions for this step is BTCUSDT for -0.5001828074455261 and ETHUSDT for 1.0\n",
      "Current holding is -0.8926538557490455 of BTCUSDT and 7.114229553253068 of ETHUSDT\n",
      "----------------------------------------\n",
      "Current profit is -10026.153603919216, cash is -26.153356382325, net worth is -26.15360391921604\n",
      "Actions for this step is BTCUSDT for 1.0010591745376587 and ETHUSDT for -0.0009878479177132249\n",
      "Current holding is -0.4460906884541402 of BTCUSDT and 7.107208711926192 of ETHUSDT\n",
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(trade0, trade1)\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Test Finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems we went bankrupcy only after a few steps.\n",
    "\n",
    "That means the learning does not work well if we only feed in historical a rolling frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoa-mdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
