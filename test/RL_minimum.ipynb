{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notebook aims to create a minimum framework of RL custom environment\n",
    "\n",
    "[gymnasium custom environment](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minimumTradeEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.observation_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "        self.action_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.random.randint(2) # {0, 1}\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # super().reset(seed=seed)\n",
    "        self.observation = self._get_obs()\n",
    "        info = {}\n",
    "        return self.observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.signal = self.observation\n",
    "        self.action = action\n",
    "        self.observation = self._get_obs()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        self.reward = 1 if self.action==self.signal else 0\n",
    "        info = {}\n",
    "\n",
    "        return self.observation, self.reward, terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        print(f\"signal: {self.signal}, action: {self.action}, reward:{self.reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = minimumTradeEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1593 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021759152 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | -0.0021     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1236        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022567851 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | -0.00426    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1222        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016646914 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | -0.00539    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1206       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01211312 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.473     |\n",
      "|    explained_variance   | -0.0159    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 77.6       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    value_loss           | 196        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1207         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075061223 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | -0.00479     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 241          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1203         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057833167 |\n",
      "|    clip_fraction        | 0.0723       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.322       |\n",
      "|    explained_variance   | -0.000965    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1196        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004535481 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | -0.00389    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1207         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024620977 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | -0.000993    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 319          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1214         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019852552 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | -0.000374    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 144          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 326          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1206         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014737883 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | -0.000503    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 152          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 335          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1211         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009978925 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | 0.000378     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    value_loss           | 342          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1213          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059515354 |\n",
      "|    clip_fraction        | 0.00649       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0854       |\n",
      "|    explained_variance   | -4.66e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 159           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    value_loss           | 350           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1210         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005403637 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0687      |\n",
      "|    explained_variance   | -9.7e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1206          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042098804 |\n",
      "|    clip_fraction        | 0.00415       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0559       |\n",
      "|    explained_variance   | 0.000311      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 163           |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    value_loss           | 354           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1209          |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021482605 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0471       |\n",
      "|    explained_variance   | -0.000132     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 164           |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.0007       |\n",
      "|    value_loss           | 357           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1212          |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016173537 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0389       |\n",
      "|    explained_variance   | -9.64e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 165           |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000605     |\n",
      "|    value_loss           | 358           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1219         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.597975e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.034       |\n",
      "|    explained_variance   | 4.02e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000131    |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1223         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.253149e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0302      |\n",
      "|    explained_variance   | 4.58e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000315    |\n",
      "|    value_loss           | 360          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1228         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003067634 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0244      |\n",
      "|    explained_variance   | -3.77e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000952    |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1233        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.32379e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0204     |\n",
      "|    explained_variance   | -3.35e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.000275   |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1239         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.495668e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0179      |\n",
      "|    explained_variance   | 0.000122     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000174    |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1246          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 37            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2298784e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0165       |\n",
      "|    explained_variance   | 9.38e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 168           |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -7.81e-05     |\n",
      "|    value_loss           | 363           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1248          |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1426974e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0153       |\n",
      "|    explained_variance   | -3.97e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 167           |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -3.8e-05      |\n",
      "|    value_loss           | 363           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1251         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.721799e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0142      |\n",
      "|    explained_variance   | -1.41e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -5.57e-05    |\n",
      "|    value_loss           | 363          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2044edf2550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, gamma=1, batch_size = 256)\n",
    "model_ppo.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'minimumTradeEnv' object has no attribute 'signal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m obs, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m model_ppo\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m      7\u001b[0m     obs, rewards, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36mminimumTradeEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, action: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, reward:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'minimumTradeEnv' object has no attribute 'signal'"
     ]
    }
   ],
   "source": [
    "env = minimumTradeEnv()\n",
    "obs, _ = env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    env.render()\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoa-mdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
