{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notebook aims to create a minimum framework of RL custom environment\n",
    "\n",
    "[gymnasium custom environment](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minimumTradeEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.observation_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "        self.action_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.random.randint(2) # {0, 1}\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # super().reset(seed=seed)\n",
    "        self.observation = self._get_obs()\n",
    "        info = {}\n",
    "        return self.observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.signal = self.observation\n",
    "        self.action = action\n",
    "        self.observation = self._get_obs()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        self.reward = 1 if self.action==self.signal else 0\n",
    "        info = {}\n",
    "\n",
    "        return self.observation, self.reward, terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        print(f\"signal: {self.signal}, action: {self.action}, reward:{self.reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = minimumTradeEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2212 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1897        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021664076 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | -0.0433     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1787       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02414863 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.641     |\n",
      "|    explained_variance   | -0.0598    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.9       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1761        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015014019 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | -0.0929     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1744        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012192477 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | -0.0822     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1736        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209027 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.391      |\n",
      "|    explained_variance   | -0.0426     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1730         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050846767 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | -0.0218      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 272          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1730        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003650139 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1721         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033996424 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | -0.00646     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    value_loss           | 303          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1710         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021178527 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | -0.00565     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1708         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016083806 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | -0.00401     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 152          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 332          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1710         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013120138 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.11        |\n",
      "|    explained_variance   | -0.00274     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 340          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1708          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065952854 |\n",
      "|    clip_fraction        | 0.00752       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0888       |\n",
      "|    explained_variance   | -0.000239     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 158           |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.00272      |\n",
      "|    value_loss           | 349           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1701          |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063543255 |\n",
      "|    clip_fraction        | 0.00742       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.07         |\n",
      "|    explained_variance   | -0.00068      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 161           |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    value_loss           | 350           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1702          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030617623 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0588       |\n",
      "|    explained_variance   | 0.000382      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 161           |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000815     |\n",
      "|    value_loss           | 354           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1702          |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027972093 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.048        |\n",
      "|    explained_variance   | -0.000872     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 161           |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000822     |\n",
      "|    value_loss           | 356           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1700         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.223365e-05 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0412      |\n",
      "|    explained_variance   | -0.000713    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000602    |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1698         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002183271 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0347      |\n",
      "|    explained_variance   | 0.000282     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000768    |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1696          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9042712e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0296       |\n",
      "|    explained_variance   | -0.000689     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 167           |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000176     |\n",
      "|    value_loss           | 361           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1697         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.969715e-05 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0251      |\n",
      "|    explained_variance   | -0.000265    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000723    |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1696        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.20767e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0223     |\n",
      "|    explained_variance   | -9.47e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.000177   |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1695          |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8334692e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0194       |\n",
      "|    explained_variance   | -0.00016      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 166           |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -0.000181     |\n",
      "|    value_loss           | 362           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1694          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2249907e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0176       |\n",
      "|    explained_variance   | 0.000279      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 165           |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000129     |\n",
      "|    value_loss           | 362           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1697          |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5663695e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0161       |\n",
      "|    explained_variance   | 2.88e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 167           |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -4.86e-05     |\n",
      "|    value_loss           | 363           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1698          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 30            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.8286255e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.015        |\n",
      "|    explained_variance   | -6.99e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 166           |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -8.19e-05     |\n",
      "|    value_loss           | 363           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20105005490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, gamma=1, batch_size = 256)\n",
    "model_ppo.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    env.render()\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoa-mdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
