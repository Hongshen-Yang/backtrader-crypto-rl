{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is notebook aims to create a minimum framework of RL custom environment\n",
    "\n",
    "[gymnasium custom environment](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minimumTradeEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.observation_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "        self.action_space = gym.spaces.Discrete(2) # {0, 1}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.random.randint(2) # {0, 1}\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # super().reset(seed=seed)\n",
    "        self.observation = self._get_obs()\n",
    "        info = {}\n",
    "        return self.observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.signal = self.observation\n",
    "        self.action = action\n",
    "        self.observation = self._get_obs()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        self.reward = 1 if self.action==self.signal else 0\n",
    "        info = {}\n",
    "\n",
    "        return self.observation, self.reward, terminated, truncated, info\n",
    "    \n",
    "    def render(self):\n",
    "        print(f\"signal: {self.signal}, action: {self.action}, reward:{self.reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = minimumTradeEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2230 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021021243 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.000379    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0503     |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1211        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011692092 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | -0.00236    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1175        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011509096 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 7.33e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1151         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084339585 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | -8.82e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1125        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006663301 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.000104    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1099        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005237949 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.38       |\n",
      "|    explained_variance   | 2.29e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041216873 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.32        |\n",
      "|    explained_variance   | 5.96e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1075         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033377884 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.266       |\n",
      "|    explained_variance   | 1.02e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64           |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1059         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027256007 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.219       |\n",
      "|    explained_variance   | -1.45e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 74.6         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1051         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020067603 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 4.65e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 81.2         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1048         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015160867 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | -2.26e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 83           |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 260          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1051         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008948238 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | -8.11e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 86.1         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    value_loss           | 268          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1052         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007787286 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0897      |\n",
      "|    explained_variance   | -3.1e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 88.9         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1051        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000699202 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0714     |\n",
      "|    explained_variance   | -6.08e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.4        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1051         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006401846 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0563      |\n",
      "|    explained_variance   | 4.17e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 89.4         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1047          |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035512814 |\n",
      "|    clip_fraction        | 0.00796       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0448       |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 90.6          |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    value_loss           | 277           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1046          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018154597 |\n",
      "|    clip_fraction        | 0.00356       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0364       |\n",
      "|    explained_variance   | -2.26e-06     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 93            |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    value_loss           | 280           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1046          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 37            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017769524 |\n",
      "|    clip_fraction        | 0.00386       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0291       |\n",
      "|    explained_variance   | -9.54e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 89.4          |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    value_loss           | 280           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1044          |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014106338 |\n",
      "|    clip_fraction        | 0.00249       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0235       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 93.7          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000857     |\n",
      "|    value_loss           | 281           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1043         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.367111e-05 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0186      |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93.1         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000513    |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1042         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.990602e-05 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.015       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 92           |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000595    |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1040         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.534092e-05 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0116      |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93.6         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000796    |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1036         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.266915e-05 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00986     |\n",
      "|    explained_variance   | 7.75e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 92.7         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000505    |\n",
      "|    value_loss           | 283          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1036          |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 49            |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015735658 |\n",
      "|    clip_fraction        | 0.00205       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00735      |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 89.9          |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.001        |\n",
      "|    value_loss           | 282           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x17859fe2430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, gamma=1)\n",
    "model_ppo.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 0, action: 0, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 1, action: 1, reward:1\n",
      "signal: 0, action: 0, reward:1\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    env.render()\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    obs, rewards, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uoa-mdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
