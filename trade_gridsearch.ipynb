{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyfolio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.gridsearch import gridsearch\n",
    "from utils.read2df import read2df\n",
    "from utils.cointncorr import CointnCorr\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import backtrader as bt\n",
    "from itertools import combinations\n",
    "\n",
    "from envs.env_gridsearch import KellyCriterionIndicator, PairTrading\n",
    "\n",
    "os.makedirs(\"result/gridsearch\", exist_ok=True)\n",
    "cointncorr_txt = f\"result/gridsearch/cointncorr.txt\"\n",
    "os.remove(cointncorr_txt) if os.path.exists(cointncorr_txt) else None\n",
    "\n",
    "strategy_txt = f\"result/gridsearch/strategy.txt\"\n",
    "os.remove(strategy_txt) if os.path.exists(strategy_txt) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from [binance-public-data](https://github.com/binance/binance-public-data/tree/master/python)\n",
    "\n",
    "Download BTCUSDT and ETHUSDT for histories after `start_date` with interested intervals.\n",
    "\n",
    "The `symbols` are the trading pairs we are interested in the pair trading.\n",
    "\n",
    "`start_date` means we will start trading from the marked date.\n",
    "\n",
    "`freqs` is a dictionary of all trading intervals to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT', 'XMRUSDT', 'BNBUSDT', 'ADAUSDT', 'DOGEUSDT', 'SOLUSDT', 'TRXUSDT']\n",
    "start_date = '2022-01-01'\n",
    "trade_date = '2023-01-01'\n",
    "\n",
    "# freqs = {'1h':60, '2h':120, '4h':240, '6h':360, '8h':480, '12h':720, '1d':1440}\n",
    "freqs = {'3m':3, '5m':5, '15m':15, '30m':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the downloaded OHLCV data into `pandas` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = read2df(symbols, freqs)\n",
    "dfs = read2df(symbols, freqs)\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains, tests = [], []\n",
    "for i in range(len(dfs)):\n",
    "    trains.append(dfs[i][(dfs[i]['datetime'] > start_date) & (dfs[i]['datetime'] < trade_date)].reset_index(drop=True))\n",
    "    tests.append(dfs[i][dfs[i]['datetime'] >= trade_date].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cointegration and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate daily coint and corr for all the pairs\n",
    "Consider 1 day with 1440 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A temp solution for speed development\n",
    "# trains2 = []\n",
    "# for i in range(len(trains)):\n",
    "#         trains2.append(trains[i].head(5000))\n",
    "\n",
    "# Takes a looooong time\n",
    "tables = CointnCorr(trains, freqs).tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cointncorr_txt, \"a\") as f:\n",
    "    for k, v in tables.items():\n",
    "        f.write(f\"{k}\\n\")\n",
    "        f.write(f\"{v}\\n\\n\")\n",
    "f.close()\n",
    "\n",
    "best_value = 0\n",
    "for key in tables.keys():\n",
    "    for freq in freqs:\n",
    "        rel = tables[key].at['coint', freq] + tables[key].at['corr', freq]\n",
    "        if rel > best_value:\n",
    "            best_value = rel\n",
    "            best_pair = key\n",
    "            best_freq = freq\n",
    "print(\"===========================================\")\n",
    "print(f\"Best trading pairs shall be: {best_pair} under {best_freq} interval\")\n",
    "print(f\"the coint is {round(tables[best_pair].at['coint', best_freq]*100, 2)}% and the corr is {round(tables[best_pair].at['corr', best_freq],3)}\")\n",
    "print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cerebro_run(datafeeds, param):\n",
    "    # Create a Cerebro instance and add the data feed\n",
    "    cerebro = bt.Cerebro()\n",
    "    # TODO: should I include `best_pair` as a parameter?\n",
    "    cerebro.adddata(datafeeds[0], name=best_pair.split('_')[0])\n",
    "    cerebro.adddata(datafeeds[1], name=best_pair.split('_')[1])\n",
    "\n",
    "    # Set up other parameters for backtest\n",
    "    cerebro.broker.set_cash(100000)  # Set initial capital\n",
    "\n",
    "    # comminfo = PairTradingCommInfo(commission=0.002, margin=1000, mult=10)\n",
    "    # cerebro.broker.addcommissioninfo(comminfo)\n",
    "\n",
    "    cerebro.addanalyzer(bt.analyzers.TimeReturn, _name='timereturns', compression=60)\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns, _name='Returns')\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "    # cerebro.addsizer(KellyCriterionSizer)\n",
    "\n",
    "    cerebro.addstrategy(PairTrading, **param)\n",
    "    strats = cerebro.run()\n",
    "    return strats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_pos = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "traindata0 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "traindata1 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[1]].reset_index(drop=True)\n",
    "\n",
    "datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=traindata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=traindata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeeds = [datafeed0, datafeed1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test run\n",
    "# https://github.com/mementum/backtrader/blob/master/backtrader/indicators/ols.py\n",
    "# It always returns weird error like the number of params\n",
    "\n",
    "# 1. The default OLS indicator is precarious, always weird errors like num of params, or sometimes index error\n",
    "# 2. The custom indicator is precious as well. not trustworthy\n",
    "\n",
    "os.remove(strategy_txt) if os.path.exists(strategy_txt) else None\n",
    "param = {'OPEN_THRE':3, 'CLOS_THRE':1, 'period':50}\n",
    "cerebro_run(datafeeds, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search the Strategy\n",
    "Define scoring and param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'OPEN_THRE':np.arange(1, 3, 1), \n",
    "#     'CLOS_THRE':np.arange(0.2, 1.0, 0.2), \n",
    "#     'period': np.arange(30, 60, 10)\n",
    "# }\n",
    "\n",
    "freq_adjust = freqs[best_freq]\n",
    "\n",
    "param_grid = {\n",
    "    'OPEN_THRE': np.arange(2, 5, 1), \n",
    "    'CLOS_THRE': np.arange(0.1, 0.4, 0.1), \n",
    "    'period': np.arange(int(400/freq_adjust), int(700/freq_adjust), int(100/freq_adjust))\n",
    "}\n",
    "\n",
    "def scoring(strats):\n",
    "    score = strats[0].analyzers.Returns.get_analysis()['rtot']\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(strategy_txt, \"a\") as f:\n",
    "    f.write(f\"Gridsearch run started\" + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "best_profit, best_params = gridsearch(cerebro_run, param_grid, scoring, datafeeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade with test data\n",
    "Get the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_position = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "testdata0 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "testdata1 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "\n",
    "test_datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=testdata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "test_datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=testdata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    ")\n",
    "\n",
    "test_datafeeds = [test_datafeed0, test_datafeed1]\n",
    "\n",
    "testdata0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(strategy_txt, \"a\") as f:\n",
    "    f.write(f\"Test run start\\n\")\n",
    "    f.write(f\"---------\\n\")\n",
    "f.close()\n",
    "\n",
    "test_res = cerebro_run(test_datafeeds, best_params)\n",
    "\n",
    "# trade_txt = \"result/gridsearch/trade.txt\"\n",
    "# os.remove(cointncorr_txt) if os.path.exists(cointncorr_txt) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted a PR for Backtrader-OLS results\n",
    "\n",
    "> https://github.com/mementum/backtrader/pull/487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze with [Pyfolio](https://pyfolio.ml4trading.io/api-reference.html)\n",
    "\n",
    "Default package has an known error issue out of lack of maintainence, requires to modify the package manually\n",
    "> https://github.com/quantopian/pyfolio/issues/652\n",
    "\n",
    "Created a github merge\n",
    "> https://github.com/quantopian/pyfolio/pull/703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pyfolio = test_res[0].analyzers.pyfolio.get_analysis()\n",
    "res_pyfolio = pd.Series(res_pyfolio['returns'])\n",
    "res_pyfolio.index = pd.to_datetime(res_pyfolio.index)\n",
    "res_pyfolio = res_pyfolio = res_pyfolio.astype('float32')\n",
    "res_pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfolio.tears.create_full_tear_sheet(returns=pd.Series(res_pyfolio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
