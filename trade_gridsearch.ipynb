{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "* Thoughts on improve the profitability\n",
    "> Should find pairs with stronger relationship\n",
    ">\n",
    "> Should use some other econometrics model to calculate the spread (?Can we use something other than OLS?)\n",
    "\n",
    "This notebook aims for providing an experiment of traditional pair trading with parameter autotuning grid search.\n",
    "\n",
    "This experiment is based on [backtrader](https://www.backtrader.com/) which has an agnosticism philosophy that the data come in as a per-sample basis. Indicators are recalculate when new data come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HSY/miniconda3/envs/uoa-mdt/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pyfolio\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import backtrader as bt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "from utils.gridsearch import gridsearch\n",
    "from utils.read2df import read2df\n",
    "from utils.cointncorr import CointnCorr\n",
    "from envs.env_gridsearch import KellyCriterionIndicator, PairTrading\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.makedirs(\"result/gridsearch\", exist_ok=True)\n",
    "\n",
    "cointncorrtxt = f\"result/gridsearch/cointncorr.txt\"\n",
    "os.remove(cointncorrtxt) if os.path.exists(cointncorrtxt) else None\n",
    "\n",
    "for root, dirs, files in os.walk(f\"result/gridsearch/\"):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Download historical data for `symbols` after `start_date` with selected `freqs` from [`binance-public-data`](https://github.com/binance/binance-public-data/tree/master/python)\n",
    "\n",
    "We will train data from `start_date` until `trade_date`, and start trade after `trade_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT', 'XMRUSDT', 'BNBUSDT', 'ADAUSDT', 'DOGEUSDT', 'SOLUSDT', 'TRXUSDT']\n",
    "start_date = '2022-01-01'\n",
    "trade_date = '2023-01-01'\n",
    "\n",
    "# freqs = {'1h':60, '2h':120, '4h':240, '6h':360, '8h':480, '12h':720, '1d':1440}\n",
    "freqs = {'3m':3, '5m':5, '15m':15, '30m':30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>itvl</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.142880</td>\n",
       "      <td>0.142740</td>\n",
       "      <td>0.142870</td>\n",
       "      <td>4.002545e+05</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>22.418300</td>\n",
       "      <td>22.418600</td>\n",
       "      <td>22.360000</td>\n",
       "      <td>22.395800</td>\n",
       "      <td>7.928640e+03</td>\n",
       "      <td>BNBUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>11854.560000</td>\n",
       "      <td>11854.570000</td>\n",
       "      <td>11842.000000</td>\n",
       "      <td>11850.140000</td>\n",
       "      <td>9.037367e+01</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>4.316000e+05</td>\n",
       "      <td>DOGEUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>395.100000</td>\n",
       "      <td>395.100000</td>\n",
       "      <td>394.530000</td>\n",
       "      <td>394.950000</td>\n",
       "      <td>6.073353e+02</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>58.310000</td>\n",
       "      <td>58.310000</td>\n",
       "      <td>58.210000</td>\n",
       "      <td>58.240000</td>\n",
       "      <td>1.662253e+03</td>\n",
       "      <td>LTCUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>3.600000e+00</td>\n",
       "      <td>SOLUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>2.575011e+06</td>\n",
       "      <td>TRXUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1597125779999</td>\n",
       "      <td>94.740000</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>94.670000</td>\n",
       "      <td>94.710000</td>\n",
       "      <td>2.343714e+02</td>\n",
       "      <td>XMRUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:02:59.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1597125959999</td>\n",
       "      <td>0.142820</td>\n",
       "      <td>0.142820</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>3.272269e+05</td>\n",
       "      <td>ADAUSDT</td>\n",
       "      <td>3m</td>\n",
       "      <td>2020-08-11 06:05:59.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time          open          high           low         close  \\\n",
       "0  1597125779999      0.142880      0.142880      0.142740      0.142870   \n",
       "1  1597125779999     22.418300     22.418600     22.360000     22.395800   \n",
       "2  1597125779999  11854.560000  11854.570000  11842.000000  11850.140000   \n",
       "3  1597125779999      0.003556      0.003559      0.003556      0.003559   \n",
       "4  1597125779999    395.100000    395.100000    394.530000    394.950000   \n",
       "5  1597125779999     58.310000     58.310000     58.210000     58.240000   \n",
       "6  1597125779999      2.850000      2.850000      2.850000      2.850000   \n",
       "7  1597125779999      0.021360      0.021360      0.021320      0.021340   \n",
       "8  1597125779999     94.740000     94.750000     94.670000     94.710000   \n",
       "9  1597125959999      0.142820      0.142820      0.142600      0.142720   \n",
       "\n",
       "         volume       tic itvl                datetime  \n",
       "0  4.002545e+05   ADAUSDT   3m 2020-08-11 06:02:59.999  \n",
       "1  7.928640e+03   BNBUSDT   3m 2020-08-11 06:02:59.999  \n",
       "2  9.037367e+01   BTCUSDT   3m 2020-08-11 06:02:59.999  \n",
       "3  4.316000e+05  DOGEUSDT   3m 2020-08-11 06:02:59.999  \n",
       "4  6.073353e+02   ETHUSDT   3m 2020-08-11 06:02:59.999  \n",
       "5  1.662253e+03   LTCUSDT   3m 2020-08-11 06:02:59.999  \n",
       "6  3.600000e+00   SOLUSDT   3m 2020-08-11 06:02:59.999  \n",
       "7  2.575011e+06   TRXUSDT   3m 2020-08-11 06:02:59.999  \n",
       "8  2.343714e+02   XMRUSDT   3m 2020-08-11 06:02:59.999  \n",
       "9  3.272269e+05   ADAUSDT   3m 2020-08-11 06:05:59.999  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read the downloaded OHLCV data into `pandas` dataframe\n",
    "'''\n",
    "\n",
    "# dfs = read2df(symbols, freqs)\n",
    "dfs = read2df(symbols, freqs)\n",
    "\n",
    "# have a preview\n",
    "dfs[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set data before `trade_data` as training data, after `trade_data` is trade_data\n",
    "'''\n",
    "\n",
    "trains, tests = [], []\n",
    "for i in range(len(dfs)):\n",
    "    trains.append(dfs[i][(dfs[i]['datetime'] > start_date) & (dfs[i]['datetime'] < trade_date)].reset_index(drop=True))\n",
    "    tests.append(dfs[i][dfs[i]['datetime'] >= trade_date].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cointegration and Correlation\n",
    "\n",
    "We need to make sure that our data is capable for pair trading. \n",
    "At least it should have the tendency to merge together therefore we test the coint and corr between every possible two pairs \n",
    "\n",
    "Calculate daily coint and corr for all the pairs\n",
    "Consider 1 day with 1440 minutes.\n",
    "\n",
    "Delete the pickle file in the `\\result` if want to recalculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Data loaded as: BTCUSDT_ETHUSDT under 15m interval\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load data from pickle or recalculate\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "# If there is already a pickle file\n",
    "pickle_file = 'result/cointncorr.pickle'\n",
    "\n",
    "if os.path.exists(pickle_file):\n",
    "    with open('result/cointncorr.pickle', 'rb') as pk:\n",
    "        data = pickle.load(pk)\n",
    "\n",
    "    freq_position = list(freqs.keys()).index(data[1])\n",
    "\n",
    "    df0 = dfs[freq_position][dfs[freq_position]['tic']==data[0][0]].reset_index(drop=True)\n",
    "    df1 = dfs[freq_position][dfs[freq_position]['tic']==data[0][1]].reset_index(drop=True)\n",
    "\n",
    "    pair, best_freq = data \n",
    "    best_pair = f\"{pair[0]}_{pair[1]}\"\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"Data loaded as: {best_pair} under {best_freq} interval\")\n",
    "    print(\"===========================================\")\n",
    "\n",
    "else: \n",
    "    # If there is no pickle file, then recalculate\n",
    "    # Takes a looooong time\n",
    "    tables = CointnCorr(trains, freqs).tabulate()\n",
    "\n",
    "    with open(cointncorrtxt, \"a\") as f:\n",
    "        for k, v in tables.items():\n",
    "            f.write(f\"{k}\\n\")\n",
    "            f.write(f\"{v}\\n\\n\")\n",
    "    f.close()\n",
    "\n",
    "    best_value = 0\n",
    "    for key in tables.keys():\n",
    "        for freq in freqs:\n",
    "            rel = tables[key].at['coint', freq] + tables[key].at['corr', freq]\n",
    "            if rel > best_value:\n",
    "                best_value = rel\n",
    "                best_pair = key\n",
    "                best_freq = freq\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"Best trading pairs shall be: {best_pair} under {best_freq} interval\")\n",
    "    print(f\"the coint is {round(tables[best_pair].at['coint', best_freq]*100, 2)}%\")\n",
    "    print(f\"and the corr is {round(tables[best_pair].at['corr', best_freq],3)}\")\n",
    "    print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cointncorr = best_pair.split(\"_\"), best_freq\n",
    "\n",
    "with open('result/cointncorr.pickle', 'wb') as pk:\n",
    "    pickle.dump(cointncorr, pk)\n",
    "    \n",
    "freq_pos = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "traindata0 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "traindata1 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[1]].reset_index(drop=True)\n",
    "\n",
    "# How come a datetime of 2022(ish) is converted to 738786.635416655???\n",
    "datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=traindata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=traindata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeeds = [datafeed0, datafeed1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Strategy\n",
    "\n",
    "We should firstly have a test run on the strategy to make sure it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted a PR for Backtrader-OLS results\n",
    "\n",
    "> https://github.com/mementum/backtrader/pull/487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cerebro_run(datafeeds, param):\n",
    "    # Create a Cerebro instance and add the data feed\n",
    "    cerebro = bt.Cerebro()\n",
    "    # TODO: should I include `best_pair` as a parameter?\n",
    "    cerebro.adddata(datafeeds[0], name=best_pair.split('_')[0])\n",
    "    cerebro.adddata(datafeeds[1], name=best_pair.split('_')[1])\n",
    "\n",
    "    # Set up other parameters for backtest\n",
    "    cerebro.broker.set_cash(100000)  # Set initial capital\n",
    "\n",
    "    # comminfo = PairTradingCommInfo(commission=0.002, margin=1000, mult=10)\n",
    "    # cerebro.broker.addcommissioninfo(comminfo)\n",
    "\n",
    "    cerebro.addanalyzer(bt.analyzers.TimeReturn, _name='timereturns', compression=60)\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns, _name='Returns')\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='tradeanalyzer')\n",
    "    # cerebro.addsizer(KellyCriterionSizer)\n",
    "\n",
    "    cerebro.addstrategy(PairTrading, **param)\n",
    "    strats = cerebro.run()\n",
    "    return strats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Open Threshold:1.5, Close Threshold:0.1, period: 10\n",
      "\n",
      "Starting Value - 100000.00\n",
      "\n",
      "Ending   Value - 89637.03\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A test run\n",
    "# https://github.com/mementum/backtrader/blob/master/backtrader/indicators/ols.py\n",
    "# It always returns weird error like the number of params\n",
    "\n",
    "# 1. The default OLS indicator is precarious, always weird errors like num of params, or sometimes index error\n",
    "# 2. The custom indicator is precious as well. not trustworthy\n",
    "\n",
    "param = {'OPEN_THRE':1.5, 'CLOS_THRE':0.1, 'period':10, 'verbose':2, 'prefix':'Experiment'}\n",
    "experiment = cerebro_run(datafeeds, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search the Strategy\n",
    "\n",
    "The grid search on all the possible results for an optimal outcome\n",
    "\n",
    "Define `scoring` function and `param_grid` for grid search\n",
    "\n",
    "then `gridsearch` from `utils.gridsearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:49<51:35, 49.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Open Threshold:2, Close Threshold:0.1, period: 6\n",
      "\n",
      "Starting Value - 100000.00\n",
      "\n",
      "Ending   Value - 80394.57\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/64 [01:36<49:35, 47.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Open Threshold:2, Close Threshold:0.1, period: 39\n",
      "\n",
      "Starting Value - 100000.00\n",
      "\n",
      "Ending   Value - 98764.21\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3/64 [02:23<48:14, 47.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Open Threshold:2, Close Threshold:0.1, period: 72\n",
      "\n",
      "Starting Value - 100000.00\n",
      "\n",
      "Ending   Value - 107462.71\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freq_adjust = freqs[best_freq]\n",
    "\n",
    "param_grid = {\n",
    "    'OPEN_THRE': np.arange(2, 10, 2), \n",
    "    'CLOS_THRE': np.arange(0.1, 8.1, 2), \n",
    "    'period': np.arange(int(100/freq_adjust), int(2000/freq_adjust), int(500/freq_adjust)),\n",
    "    'verbose': [2],\n",
    "    'prefix': ['Gridsearch']\n",
    "}\n",
    "\n",
    "def scoring(strats):\n",
    "    score = strats[0].analyzers.Returns.get_analysis()['rtot']\n",
    "    return score\n",
    "\n",
    "# included tqdm for progress bar\n",
    "# Take a loooong time\n",
    "best_profit, best_params, best_result = gridsearch(cerebro_run, param_grid, scoring, datafeeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade with test data\n",
    "Use the parameter tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_position = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "testdata0 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "testdata1 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[1]].reset_index(drop=True)\n",
    "\n",
    "test_datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=testdata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "test_datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=testdata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    ")\n",
    "\n",
    "test_datafeeds = [test_datafeed0, test_datafeed1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['verbose']=2\n",
    "best_params['prefix']= 'Test'\n",
    "# test_res = cerebro_run(test_datafeeds, best_params)\n",
    "\n",
    "test_res = cerebro_run(test_datafeeds, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze with [Pyfolio](https://pyfolio.ml4trading.io/api-reference.html)\n",
    "\n",
    "#TODO: We need find a way to calculate the per arbitrage data!... or should we?\n",
    "\n",
    "Default package has an known error issue out of lack of maintainence, requires to modify the package manually\n",
    "> https://github.com/quantopian/pyfolio/issues/652\n",
    "\n",
    "Created a github merge\n",
    "> https://github.com/quantopian/pyfolio/pull/703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_pyfolio = test_res[0].analyzers.pyfolio.get_analysis()\n",
    "# res_pyfolio = pd.Series(res_pyfolio['returns'])\n",
    "# res_pyfolio.index = pd.to_datetime(res_pyfolio.index)\n",
    "# res_pyfolio = res_pyfolio.astype('float32')\n",
    "# res_pyfolio\n",
    "\n",
    "def pyfolio_process(res):\n",
    "    res_pyfolio = res[0].analyzers.pyfolio.get_analysis()\n",
    "    res_pyfolio = pd.Series(res_pyfolio['returns'])\n",
    "    res_pyfolio.index = pd.to_datetime(res_pyfolio.index)\n",
    "    res_pyfolio = res_pyfolio.astype('float32')\n",
    "    return res_pyfolio\n",
    "\n",
    "test_pyfolio = pyfolio_process(test_res)\n",
    "grid_pyfolio = pyfolio_process(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tradeanalyzer = best_result[0].analyzers.tradeanalyzer.get_analysis()\n",
    "print(json.dumps(grid_tradeanalyzer, indent = 2))\n",
    "\n",
    "pyfolio.tears.create_full_tear_sheet(returns=pd.Series(grid_pyfolio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tradeanalyzer = test_res[0].analyzers.tradeanalyzer.get_analysis()\n",
    "print(json.dumps(res_tradeanalyzer, indent = 2))\n",
    "\n",
    "pyfolio.tears.create_full_tear_sheet(returns=pd.Series(test_pyfolio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the text file and split it into individual trades\n",
    "with open('result/gridsearch/Test_BTCUSDT_ETHUSDT_O35C1P33.txt', 'r') as file:\n",
    "    trades = file.read().split('---- Close Position @ ')\n",
    "\n",
    "# Initialize lists to store trade details\n",
    "dates, buy_currency, sell_currency, buy_price, sell_price, buy_qty, sell_qty = [], [], [], [], [], [], [], []\n",
    "\n",
    "# Loop through the trades and extract details\n",
    "for trade in trades:\n",
    "    trade_details = trade.split('\\n')\n",
    "    \n",
    "    # Check if the required data exists in this trade block\n",
    "    if len(trade_details) < 3:\n",
    "        continue\n",
    "    \n",
    "    date = trade_details[0].split('@ ')[1].strip()\n",
    "    dates.append(date)\n",
    "\n",
    "    buy_sell_1 = trade_details[1].split()\n",
    "    buy_currency.append(buy_sell_1[1])\n",
    "    buy_price.append(float(buy_sell_1[4]))\n",
    "    buy_qty.append(float(buy_sell_1[8]))\n",
    "\n",
    "    sell_currency_2 = trade_details[2].split()\n",
    "    sell_currency.append(sell_currency_2[1])\n",
    "    sell_price.append(float(sell_currency_2[4]))\n",
    "    sell_qty.append(float(sell_currency_2[8]))\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Date': dates,\n",
    "    'Buy Currency': buy_currency,\n",
    "    'Buy Price': buy_price,\n",
    "    'Buy Quantity': buy_qty,\n",
    "    'Sell Currency': sell_currency,\n",
    "    'Sell Price': sell_price,\n",
    "    'Sell Quantity': sell_qty\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "541px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
