{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "* Thoughts on improve the profitability\n",
    "> Should find pairs with stronger relationship\n",
    ">\n",
    "> Should use some other econometrics model to calculate the spread (?Can we use something other than OLS?)\n",
    "\n",
    "This notebook aims for providing an experiment of traditional pair trading with parameter autotuning grid search.\n",
    "\n",
    "This experiment is based on [backtrader](https://www.backtrader.com/) which has an agnosticism philosophy that the data come in as a per-sample basis. Indicators are recalculate when new data come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pyfolio\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import backtrader as bt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "# Find parameters in `params.py`\n",
    "from params import *\n",
    "from utils.gridsearch import gridsearch\n",
    "from utils.read2df import read2df\n",
    "from utils.cointncorr import CointnCorr\n",
    "from utils.resanalyse import res_analyse\n",
    "from utils.pyfolioprocess import pyfolio_process\n",
    "from envs.env_gridsearch import KellyCriterionIndicator, PairTrading\n",
    "\n",
    "cointncorrtxt = f\"result/gridsearch/cointncorr.txt\"\n",
    "\n",
    "os.makedirs(\"result/gridsearch\", exist_ok=True)\n",
    "os.remove(cointncorrtxt) if os.path.exists(cointncorrtxt) else None\n",
    "\n",
    "for root, dirs, files in os.walk(f\"result/gridsearch/\"):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Download historical data for `symbols` after `start_date` with selected `freqs` from [`binance-public-data`](https://github.com/binance/binance-public-data/tree/master/python)\n",
    "\n",
    "We will train data from `start_date` until `trade_date`, and start trade after `trade_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read the downloaded OHLCV data into `pandas` dataframe\n",
    "'''\n",
    "\n",
    "# dfs = read2df(symbols, freqs)\n",
    "dfs = read2df(symbols, freqs)\n",
    "\n",
    "# have a preview\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set data before `trade_data` as training data, after `trade_data` is trade_data\n",
    "'''\n",
    "\n",
    "trains, tests = [], []\n",
    "for i in range(len(dfs)):\n",
    "    trains.append(dfs[i][(dfs[i]['datetime'] > start_date) & (dfs[i]['datetime'] < trade_date)].reset_index(drop=True))\n",
    "    tests.append(dfs[i][dfs[i]['datetime'] >= trade_date].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cointegration and Correlation\n",
    "\n",
    "We need to make sure that our data is capable for pair trading. \n",
    "At least it should have the tendency to merge together therefore we test the coint and corr between every possible two pairs \n",
    "\n",
    "Calculate daily coint and corr for all the pairs\n",
    "Consider 1 day with 1440 minutes.\n",
    "\n",
    "Delete the pickle file in the `\\result` if want to recalculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load data from pickle or recalculate\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "# If there is already a pickle file\n",
    "pickle_file = 'result/cointncorr.pickle'\n",
    "\n",
    "if os.path.exists(pickle_file):\n",
    "    with open('result/cointncorr.pickle', 'rb') as pk:\n",
    "        data = pickle.load(pk)\n",
    "\n",
    "    freq_position = list(freqs.keys()).index(data[1])\n",
    "\n",
    "    df0 = dfs[freq_position][dfs[freq_position]['tic']==data[0][0]].reset_index(drop=True)\n",
    "    df1 = dfs[freq_position][dfs[freq_position]['tic']==data[0][1]].reset_index(drop=True)\n",
    "\n",
    "    pair, best_freq = data \n",
    "    best_pair = f\"{pair[0]}_{pair[1]}\"\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"Data loaded as: {best_pair} under {best_freq} interval\")\n",
    "    print(\"===========================================\")\n",
    "\n",
    "else: \n",
    "    # If there is no pickle file, then recalculate\n",
    "    # Takes a looooong time\n",
    "    tables = CointnCorr(trains, freqs).tabulate()\n",
    "\n",
    "    with open(cointncorrtxt, \"a\") as f:\n",
    "        for k, v in tables.items():\n",
    "            f.write(f\"{k}\\n\")\n",
    "            f.write(f\"{v}\\n\\n\")\n",
    "    f.close()\n",
    "\n",
    "    best_value = 0\n",
    "    for key in tables.keys():\n",
    "        for freq in freqs:\n",
    "            rel = tables[key].at['coint', freq] + tables[key].at['corr', freq]\n",
    "            if rel > best_value:\n",
    "                best_value = rel\n",
    "                best_pair = key\n",
    "                best_freq = freq\n",
    "\n",
    "    print(\"===========================================\")\n",
    "    print(f\"Best trading pairs shall be: {best_pair} under {best_freq} interval\")\n",
    "    print(f\"the coint is {round(tables[best_pair].at['coint', best_freq]*100, 2)}%\")\n",
    "    print(f\"and the corr is {round(tables[best_pair].at['corr', best_freq],3)}\")\n",
    "    print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df0['datetime'], df0['close']-df1['close'], linewidth=0.5)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Pair Distance')\n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cointncorr = best_pair.split(\"_\"), best_freq\n",
    "\n",
    "with open('result/cointncorr.pickle', 'wb') as pk:\n",
    "    pickle.dump(cointncorr, pk)\n",
    "    \n",
    "freq_pos = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "traindata0 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "traindata1 = trains[freq_pos][trains[freq_pos]['tic']==best_pair.split('_')[1]].reset_index(drop=True)\n",
    "\n",
    "# How come a datetime of 2022(ish) is converted to 738786.635416655???\n",
    "datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=traindata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=traindata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "datafeeds = [datafeed0, datafeed1]\n",
    "print(f\"length of train set is {len(traindata0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Strategy\n",
    "\n",
    "We should firstly have a test run on the strategy to make sure it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted a PR for Backtrader-OLS results\n",
    "\n",
    "> https://github.com/mementum/backtrader/pull/487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cerebro_run(datafeeds, param):\n",
    "    # Create a Cerebro instance and add the data feed\n",
    "    cerebro = bt.Cerebro()\n",
    "    # TODO: should I include `best_pair` as a parameter?\n",
    "    cerebro.adddata(datafeeds[0], name=best_pair.split('_')[0])\n",
    "    cerebro.adddata(datafeeds[1], name=best_pair.split('_')[1])\n",
    "\n",
    "    # Set up other parameters for backtest\n",
    "    cerebro.broker.set_cash(100000)  # Set initial capital\n",
    "\n",
    "    # Binance fee structure\n",
    "    # https://www.binance.com/en-BH/support/faq/binance-futures-fee-structure-fee-calculations-360033544231\n",
    "    # cerebro.broker.setcommission(commission=0.001) \n",
    "\n",
    "    # comminfo = PairTradingCommInfo(commission=0.002, margin=1000, mult=10)\n",
    "    # cerebro.broker.addcommissioninfo(comminfo)\n",
    "\n",
    "    cerebro.addanalyzer(bt.analyzers.TimeReturn, _name='timereturns', compression=60)\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns, _name='Returns')\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='tradeanalyzer')\n",
    "    # cerebro.addsizer(KellyCriterionSizer)\n",
    "\n",
    "    cerebro.addstrategy(PairTrading, **param)\n",
    "    strats = cerebro.run()\n",
    "    return strats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A test run\n",
    "# https://github.com/mementum/backtrader/blob/master/backtrader/indicators/ols.py\n",
    "# It always returns weird error like the number of params\n",
    "\n",
    "# 1. The default OLS indicator is precarious, always weird errors like num of params, or sometimes index error\n",
    "# 2. The custom indicator is precious as well. not trustworthy\n",
    "\n",
    "param = {'OPEN_THRE':7, 'CLOS_THRE':0.1, 'period':1000, 'verbose':2, 'prefix':'Experiment'}\n",
    "experiment = cerebro_run(datafeeds, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search the Strategy\n",
    "\n",
    "The grid search on all the possible results for an optimal outcome\n",
    "\n",
    "Define `scoring` function and `param_grid` for grid search\n",
    "\n",
    "then `gridsearch` from `utils.gridsearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafeeds = [datafeed0, datafeed1]\n",
    "freq_adjust = freqs[best_freq]\n",
    "\n",
    "'''\n",
    "Seems longer period provides better result\n",
    "I guess its because the zscore is relatively stabler\n",
    "'''\n",
    "param_grid = {\n",
    "    'OPEN_THRE': [2.0], # np.arange(2.2, 2.3, 0.1), \n",
    "    'CLOS_THRE': [0.1], # np.arange(0.1, 0.3, 0.2), \n",
    "    'period': [1000], # np.arange(800, 1200, 200),\n",
    "    'verbose': [0],\n",
    "    'prefix': ['Gridsearch']\n",
    "}\n",
    "\n",
    "def scoring(strats):\n",
    "    score = strats[0].analyzers.Returns.get_analysis()['rtot']\n",
    "    return score\n",
    "\n",
    "# included tqdm for progress bar\n",
    "# Take a loooong time\n",
    "best_profit, best_params, best_result = gridsearch(cerebro_run, param_grid, scoring, datafeeds)\n",
    "\n",
    "print(f\"Best parameters as: {best_params}\")\n",
    "print(f\"Best profit as: {best_profit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_position = list(freqs.keys()).index(best_freq)\n",
    "\n",
    "testdata0 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[0]].reset_index(drop=True)\n",
    "testdata1 = tests[freq_position][tests[freq_position]['tic']==best_pair.split('_')[1]].reset_index(drop=True)\n",
    "\n",
    "test_datafeed0 = bt.feeds.PandasData(\n",
    "        dataname=testdata0,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    "    )\n",
    "\n",
    "test_datafeed1 = bt.feeds.PandasData(\n",
    "        dataname=testdata1,\n",
    "        datetime='datetime',\n",
    "        open='open',\n",
    "        high='high',\n",
    "        low='low',\n",
    "        close='close',\n",
    "        volume='volume',\n",
    "        openinterest=None,\n",
    ")\n",
    "\n",
    "test_datafeeds = [test_datafeed0, test_datafeed1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['verbose']=2\n",
    "best_params['prefix']= 'Test'\n",
    "# test_res = cerebro_run(test_datafeeds, best_params)\n",
    "\n",
    "test_res = cerebro_run(test_datafeeds, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze with [Pyfolio](https://pyfolio.ml4trading.io/api-reference.html)\n",
    "\n",
    "#TODO: We need find a way to calculate the per arbitrage data!... or should we?\n",
    "\n",
    "Default package has an known error issue out of lack of maintainence, requires to modify the package manually\n",
    "> https://github.com/quantopian/pyfolio/issues/652\n",
    "\n",
    "Created a github merge\n",
    "> https://github.com/quantopian/pyfolio/pull/703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the grid search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tradeanalyzer = best_result[0].analyzers.tradeanalyzer.get_analysis()\n",
    "res_analyse(grid_tradeanalyzer)\n",
    "\n",
    "grid_pyfolio = pyfolio_process(best_result)\n",
    "pyfolio.tears.create_full_tear_sheet(returns=pd.Series(grid_pyfolio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tradeanalyzer = test_res[0].analyzers.tradeanalyzer.get_analysis()\n",
    "res_analyse(res_tradeanalyzer)\n",
    "\n",
    "test_pyfolio = pyfolio_process(test_res)\n",
    "pyfolio.tears.create_full_tear_sheet(returns=pd.Series(test_pyfolio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "541px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
