{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a custom Environment for Pair Trading\n",
    "\n",
    "Some examples on the market\n",
    "* [custom env example](https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb#scrollTo=RqxatIwPOXe_)\n",
    "* [StockTradingEnv by Adam King](https://github.com/notadamking/Stock-Trading-Environment)\n",
    "* [FinRL](https://github.com/AI4Finance-Foundation/FinRL)\n",
    "\n",
    "Target is to construct a custom Env for pair trading\n",
    "\n",
    "This env allows the learner to hold a position as a percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, csv, math, pickle, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gymnasium import spaces\n",
    "from datetime import date\n",
    "from envs.env_gridsearch import kellycriterion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from utils.read2df import read2df\n",
    "from utils.rlmetrics import get_return, get_metrics\n",
    "from utils.clearlogs import clear_logs\n",
    "\n",
    "# Find parameters in `params.py`\n",
    "from params import *\n",
    "from envs.env_rl_freeop import PairTradingEnv\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "import quantstats as qs\n",
    "\n",
    "folder_path = f\"result/rl-freeop-thres\"\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from `preliminaries.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/cointncorr.pickle', 'rb') as pk:\n",
    "    data = pickle.load(pk)\n",
    "\n",
    "dfs = read2df(symbols=data[0], freqs={data[1]: freqs[data[1]]})\n",
    "\n",
    "df0 = dfs[0][dfs[0]['tic']==data[0][0]].reset_index(drop=True)\n",
    "df1 = dfs[0][dfs[0]['tic']==data[0][1]].reset_index(drop=True)\n",
    "\n",
    "# Because we want to calculate profit based on BTC. Hence the price need to be changed.\n",
    "df0 = df0[['time', 'close', 'volume', 'tic', 'itvl', 'datetime']]\n",
    "df0['close'] = df0['close'].apply(lambda x: 1/x)\n",
    "\n",
    "df1 = df1[['time', 'close', 'volume', 'tic', 'itvl', 'datetime']]\n",
    "df1['close'] = df1['close'].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of our training data: 1331282\n"
     ]
    }
   ],
   "source": [
    "train0 = df0[df0['datetime'] < trade_date]\n",
    "train1 = df1[df1['datetime'] < trade_date]\n",
    "\n",
    "test0 = df0[df0['datetime'] >= trade_date]\n",
    "test1 = df1[df1['datetime'] >= trade_date]\n",
    "\n",
    "print(f\"The length of our training data: {len(train0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with baselin3 `env_checker`\n",
    "\n",
    "Check if the env meets the requirements of `stable_baseline3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "# > UserWarning: The action space is not based off a numpy array. Typically this means it's either a Dict or Tuple space. This type of action space is currently not supported by Stable Baselines 3. You should try to flatten the action using a wrapper.\n",
    "# Baseline 3 does not support Dict/Tuple action spaces....only Box Discrete MultiDiscrete MultiBinary\n",
    "# Is there another way to achieve the same functionality?\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do an experiment run with randomly generated actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PairTradingEnv(train0, train1, tc=0.002, verbose=1, model=f\"{folder_path}/networth_experiment.csv\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(f\"observation_space: {env.observation_space}\")\n",
    "print(f\"action_space: {env.action_space}\")\n",
    "print(f\"action_space.sample: {env.action_space.sample()}\")\n",
    "\n",
    "n_steps = 20\n",
    "\n",
    "for step in range(n_steps):\n",
    "    obs, reward, terminated, truncated, info = env.step(action=env.action_space.sample())\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models from stable_baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete existing tensorboard logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = f\"logs/freeop_thres/\"\n",
    "clear_logs(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PPO'''\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0.00, model=f\"{folder_path}/networth_ppo.csv\")\n",
    "\n",
    "model_ppo = PPO(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=log_path)\n",
    "model_ppo.learn(total_timesteps=250000)\n",
    "model_ppo.save(f\"{folder_path}/ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A2C'''\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0.00, model=f\"{folder_path}/networth_a2c.csv\")\n",
    "\n",
    "model_a2c = A2C(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=log_path)\n",
    "model_a2c.learn(total_timesteps=250000)\n",
    "model_a2c.save(f\"{folder_path}/a2c_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DQN'''\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0.00, model=f\"{folder_path}/networth_dqn.csv\")\n",
    "\n",
    "model_dqn = DQN(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=log_path)\n",
    "model_dqn.learn(total_timesteps=250000)\n",
    "model_dqn.save(f\"{folder_path}/dqn_pairtrading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model_ppo, model_a2c, model_dqn\n",
    "\n",
    "model_ppo = PPO.load(f\"{folder_path}/ppo_pairtrading.zip\")\n",
    "model_a2c = A2C.load(f\"{folder_path}/a2c_pairtrading.zip\")\n",
    "model_dqn = DQN.load(f\"{folder_path}/dqn_pairtrading.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(f\"{folder_path}/networth_ppo.csv\")\n",
    "    print(\"existing networth_ppo.csv removed\")\n",
    "except OSError:\n",
    "    print(\"currently no ppo results\")\n",
    "\n",
    "env = PairTradingEnv(test0, test1, tc=0, model=f\"{folder_path}/networth_ppo.csv\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while True:\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(f\"{folder_path}/networth_a2c.csv\")\n",
    "    print(\"existing networth_a2c.csv removed\")\n",
    "except OSError:\n",
    "    print(\"currently no a2c results\")\n",
    "\n",
    "env = PairTradingEnv(test0, test1, tc=0, model=f\"{folder_path}/networth_a2c.csv\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while True:\n",
    "    action, _states = model_a2c.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(f\"{folder_path}/networth_dqn.csv\")\n",
    "    print(\"existing networth_dqn.csv removed\")\n",
    "except OSError:\n",
    "    print(\"currently no dqn results\")\n",
    "\n",
    "env = PairTradingEnv(test0, test1, tc=0, model=f\"{folder_path}/networth_dqn.csv\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "while True:\n",
    "    action, _states = model_dqn.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze with Quanstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ending capital of networth_a2c.csv is ['2023-11-30 23:59:59.999000', '1.0050117117453161']\n",
      "The ending capital of networth_dqn.csv is ['2023-11-30 23:59:59.999000', '0.9367524505226877']\n",
      "The ending capital of networth_ppo.csv is ['2023-11-30 23:59:59.999000', '0.9716774768940373']\n",
      "The best model is networth_a2c.csv\n"
     ]
    }
   ],
   "source": [
    "os.remove(f\"{folder_path}/networth_experiment.csv\") if os.path.exists(f\"{folder_path}/networth_experiment.csv\") else None\n",
    "\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "best_res, best_model = None, None\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        # Loop through the lines in the CSV file\n",
    "        last_line = None\n",
    "        for row in csv_reader:\n",
    "            last_line = row  # Update last_line with the current row\n",
    "    \n",
    "    if best_res is None or float(best_res) < float(last_line[1]):\n",
    "        best_res = last_line[1]\n",
    "        best_model = file_name\n",
    "\n",
    "    print(f\"The ending capital of {file_name} is {last_line[0:2]}\")\n",
    "\n",
    "print(f\"The best model is {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound annual growth rate: 0%\n",
      "Total orders count: 479875\n",
      "Total long action: 175931\n",
      "Total short action: 303941\n",
      "Won orders count: 175931\n",
      "Lost orders count: 303941\n",
      "Win/Loss order ratio: 0.5788327339845563\n",
      "Avg order pnl: -3.396285377382514e-08\n",
      "Avg order pnl won: 0.007274615792710733\n",
      "Avg order pnl lost: -0.012567495757212901\n",
      "Avg long order pnl: nan\n",
      "Avg short order pnl: 8.920419038649659e-08\n",
      "                           values  action    zscore  position       pnl  \\\n",
      "datetime                                                                  \n",
      "2023-01-01 16:43:59.999  0.988714       0  1.839629  1.000000 -0.011274   \n",
      "2023-01-01 16:44:59.999  0.999988       0  1.084361 -0.000197 -0.011304   \n",
      "2023-01-01 16:45:59.999  1.011292       0  1.