{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a custom Environment for Pair Trading\n",
    "\n",
    "Some examples on the market\n",
    "* [custom env example](https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb#scrollTo=RqxatIwPOXe_)\n",
    "* [StockTradingEnv by Adam King](https://github.com/notadamking/Stock-Trading-Environment)\n",
    "* [FinRL](https://github.com/AI4Finance-Foundation/FinRL)\n",
    "\n",
    "Target is to construct a custom Env for pair trading\n",
    "This env restrict the behaviour of RL learner to pair trading only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gymnasium import spaces\n",
    "from datetime import date\n",
    "from envs.env_gridsearch import kellycriterion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from utils.read2df import read2df\n",
    "from params import *\n",
    "\n",
    "os.makedirs(\"result/rl-restrict\", exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(f\"result/rl-restrict/\"):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))\n",
    "\n",
    "PERIOD = 150 # Only look at the current price\n",
    "CASH = 10000\n",
    "ISKELLY = True\n",
    "OPEN_THRE = 4.0\n",
    "CLOS_THRE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from `preliminaries.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('result/cointncorr.pickle', 'rb') as pk:\n",
    "    data = pickle.load(pk)\n",
    "\n",
    "dfs = read2df(symbols=data[0], freqs={data[1]: freqs[data[1]]})\n",
    "\n",
    "df0 = dfs[0][dfs[0]['tic']==data[0][0]].reset_index(drop=True)\n",
    "df1 = dfs[0][dfs[0]['tic']==data[0][1]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of our training data: 1589703\n"
     ]
    }
   ],
   "source": [
    "train0 = df0[df0['datetime'] < trade_date]\n",
    "train1 = df1[df1['datetime'] < trade_date]\n",
    "\n",
    "test0 = df0[df0['datetime'] >= trade_date]\n",
    "test1 = df1[df1['datetime'] >= trade_date]\n",
    "\n",
    "print(f\"The length of our training data: {len(train0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom Environment\n",
    "\n",
    "The behaviour of RL learner is restricted. \n",
    "\n",
    "The action is defined as discrete actions -1, 0, 1\n",
    "\n",
    "-1 means short df0 long df1, 0 means close position, +1 means long df0 short df1\n",
    "\n",
    "> Baseline3 does not allow negative descrete space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lookback period for the observation space\n",
    "\n",
    "class PairTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    # for pair trading, we need to feed in two OHLCV dataframes\n",
    "    def __init__(self, df0, df1, tc=0.001, period=PERIOD, cash=CASH, isKelly=ISKELLY, model=\"\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if not df0['time'].equals(df1['time']):\n",
    "            raise ValueError(\"Two dataframe must have same time index\")\n",
    "\n",
    "        self.cash = cash\n",
    "        self.period = period\n",
    "        self.model = model\n",
    "\n",
    "        # transaction cost\n",
    "        self.tc = tc\n",
    "        # Whether to use Kelly or not\n",
    "        self.isKelly = isKelly\n",
    "\n",
    "        self.df0 = df0[['close', 'datetime']]\n",
    "        self.df1 = df1[['close', 'datetime']]\n",
    "\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        # Baseline 3 does not support Dict/Tuple action spaces....only Box Discrete MultiDiscrete MultiBinary\n",
    "        self.action_space = spaces.Discrete(4) # actions: {0: short p0 long p1, 1: close, 2: long p0 short p1, 3: do nothing}\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"compare_open_thre\": spaces.Discrete(3), # {0: above positive thres, 1: in between, 2: below negative thres}\n",
    "            \"compare_clos_thre\": spaces.Discrete(3), # {0: above positive thres, 1: in between, 2: below negative thres}\n",
    "            \"zscore\":     spaces.Box(low=-np.inf, high=np.inf, dtype=np.float64),\n",
    "            \"position\":   spaces.Discrete(3), # {0: short leg0 long leg1, 1: none, 2: long leg0 short leg1}\n",
    "        })\n",
    "\n",
    "        # if the length is 35, then the index shall be 0~34\n",
    "        self.max_steps = len(df0)-1\n",
    "    \n",
    "    def _kellycriterion(self, direct):\n",
    "        # direct is +1 or -1\n",
    "        spreads = pd.Series(self.distance[-self.period:-1]) * direct   \n",
    "        kc_f = kellycriterion(spreads)\n",
    "\n",
    "        return kc_f\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # The current step is always higher than the PERIOD as defined in the \n",
    "\n",
    "        prices0 = self.df0['close'].iloc[self.current_step-self.period: self.current_step]\n",
    "        prices1 = self.df1['close'].iloc[self.current_step-self.period: self.current_step]\n",
    "\n",
    "        self.distance = [x - y for x, y in zip(prices0, prices1)]\n",
    "        zscore = (self.distance[-1] - np.mean(self.distance)) / np.std(self.distance)\n",
    "\n",
    "        '''The OPEN_THRE and CLOS_THRE comes from trade_gridsearch'''\n",
    "        open_thre = OPEN_THRE\n",
    "        clos_thre = CLOS_THRE\n",
    "        compare_open_thre = 0 if zscore > open_thre else 2 if zscore < -open_thre else 1\n",
    "        compare_clos_thre = 0 if zscore > clos_thre else 2 if zscore < -open_thre else 1\n",
    "        \n",
    "        obs = {\n",
    "            \"compare_open_thre\": compare_open_thre,\n",
    "            \"compare_clos_thre\": compare_clos_thre,\n",
    "            \"zscore\": np.array([zscore]),\n",
    "            \"position\": self.position,\n",
    "        }\n",
    "        \n",
    "        return obs\n",
    "\n",
    "    def _close_position(self):\n",
    "        order_amount0 = -self.holding0\n",
    "        order_amount1 = -self.holding1\n",
    "\n",
    "        order_value0 = order_amount0 * self.curr_price0\n",
    "        order_value1 = order_amount1 * self.curr_price1\n",
    "        tc_cost = (abs(order_value0) + abs(order_value1)) * self.tc\n",
    "\n",
    "        self.cash -= order_value0 + order_value1 + tc_cost\n",
    "        self.holding0 = 0\n",
    "        self.holding1 = 0\n",
    "        self.position = 1\n",
    "\n",
    "        self.order_amount0 = order_amount0\n",
    "        self.order_amount1 = order_amount1\n",
    "\n",
    "    def _open_position(self):\n",
    "\n",
    "        # evaluate purchasing power \n",
    "        max_amount0 = self.cash/self.curr_price0\n",
    "        max_amount1 = self.cash/self.curr_price1\n",
    "\n",
    "        direction = self.action-1\n",
    "        kc = self._kellycriterion(direct=direction) if self.isKelly else 1\n",
    "        order_amount0 = direction * max_amount0 * kc\n",
    "        order_amount1 = -direction * max_amount1 * kc\n",
    "\n",
    "        order_value0 = order_amount0 * self.curr_price0\n",
    "        order_value1 = order_amount1 * self.curr_price1\n",
    "        tc_cost = (np.abs(order_value0) + np.abs(order_value1)) * self.tc\n",
    "\n",
    "        # Open a new position\n",
    "        self.cash -= order_value0 + order_value1 + tc_cost\n",
    "        self.holding0 = order_amount0\n",
    "        self.holding1 = order_amount1\n",
    "        self.position = 1 if kc==0 else self.action\n",
    "\n",
    "        self.kc = kc\n",
    "        self.order_amount0 = order_amount0\n",
    "        self.order_amount1 = order_amount1\n",
    "\n",
    "    def _reverse_position(self):\n",
    "        max_amount0 = self.cash/self.curr_price0\n",
    "        max_amount1 = self.cash/self.curr_price1\n",
    "\n",
    "        direction = self.action-1\n",
    "        kc = self._kellycriterion(direct=direction) if self.isKelly else 1\n",
    "        order_amount0 = direction * max_amount0 * kc - self.holding0\n",
    "        order_amount1 = -direction * max_amount1 * kc - self.holding1\n",
    "\n",
    "        order_value0 = order_amount0 * self.curr_price0\n",
    "        order_value1 = order_amount1 * self.curr_price1\n",
    "        tc_cost = (np.abs(order_value0) + np.abs(order_value1)) * self.tc\n",
    "\n",
    "        self.cash -= order_value0 + order_value1 + tc_cost\n",
    "        self.holding0 += order_amount0\n",
    "        self.holding1 += order_amount1\n",
    "        self.position = 1 if kc==0 else self.action\n",
    "\n",
    "        # for debugging\n",
    "        self.kc = kc\n",
    "        self.order_amount0 = order_amount0\n",
    "        self.order_amount1 = order_amount1\n",
    "\n",
    "    def _take_action(self, action):\n",
    "\n",
    "        # Record current net_worth to prev_net_worth\n",
    "        self.prev_net_worth = self.net_worth\n",
    "\n",
    "        self.curr_price0 = self.df0['close'].iloc[self.current_step]\n",
    "        self.curr_price1 = self.df1['close'].iloc[self.current_step]\n",
    "\n",
    "        self.action = action\n",
    "        \n",
    "        if self.action == 1:\n",
    "            self._close_position()\n",
    "\n",
    "        elif self.action == 0:\n",
    "            if self.position  == 1:\n",
    "                self._open_position()\n",
    "            \n",
    "            elif self.position == 2:\n",
    "                self._reverse_position()\n",
    "    \n",
    "        elif self.action == 2:\n",
    "            if self.position == 0:\n",
    "                self._reverse_position()\n",
    "\n",
    "            elif self.position == 1:\n",
    "                self._open_position()\n",
    "\n",
    "        # We record the net_worth from previous period to prev_net_worth\n",
    "        self.net_worth = self.cash + self.holding0 * self.curr_price0 + self.holding1*self.curr_price1\n",
    "\n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "\n",
    "        self.observation = self._next_observation()\n",
    "        reward = self.net_worth - self.prev_net_worth\n",
    "        terminated = bool(self.current_step >= self.max_steps)\n",
    "        truncated = bool(self.net_worth <= 0)\n",
    "        info = {}\n",
    "\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.cash = self.cash\n",
    "        self.net_worth = self.cash\n",
    "        self.prev_net_worth = self.cash\n",
    "        self.position = 0\n",
    "        self.render_step = 0\n",
    "        \n",
    "        self.holding0 = 0\n",
    "        self.holding1 = 0\n",
    "        self.order_amount0 = 0\n",
    "        self.order_amount1 = 0\n",
    "        self.kc = 0\n",
    "\n",
    "        self.current_step = np.random.randint(self.period, self.max_steps)\n",
    "\n",
    "        return self._next_observation(), {}\n",
    "    \n",
    "    def render(self):\n",
    "        profit = self.net_worth - self.cash\n",
    "        \n",
    "        # print(\n",
    "        #     # f\"direction: {self.action-1} \"\n",
    "        #     f\"networth: {self.net_worth}, \" \n",
    "        #     f\"action: {self.action}, position: {self.position}, kc: {self.kc} \"\n",
    "        #     f\"order_amount0: {self.order_amount0}, order_amount1: {self.order_amount1} \"\n",
    "        #     f\"holding0: {self.holding0}, holding1: {self.holding1} \"\n",
    "        #     f\"cash: {self.cash}, curr_price0: {self.curr_price0}, curr_price1: {self.curr_price1} \"\n",
    "        # )\n",
    "            \n",
    "        with open(f\"result/rl-restrict/networth_{self.model}.csv\", mode='a', newline='') as csv_f:\n",
    "            writer = csv.writer(csv_f)\n",
    "            writer.writerow(\n",
    "                [self.df0['datetime'].iloc[self.current_step], \n",
    "                self.net_worth]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with baselin3 `env_checker`\n",
    "\n",
    "Check if the env meets the requirements of `stable_baseline3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "# > UserWarning: The action space is not based off a numpy array. Typically this means it's either a Dict or Tuple space. This type of action space is currently not supported by Stable Baselines 3. You should try to flatten the action using a wrapper.\n",
    "# Baseline 3 does not support Dict/Tuple action spaces....only Box Discrete MultiDiscrete MultiBinary\n",
    "# Is there another way to achieve the same functionality?\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a test run with random generated actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space: Dict('compare_clos_thre': Discrete(3), 'compare_open_thre': Discrete(3), 'position': Discrete(3), 'zscore': Box(-inf, inf, (1,), float64))\n",
      "action_space: Discrete(4)\n",
      "action_space.sample: 2\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(train0, train1, tc=0, model=\"test\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(f\"observation_space: {env.observation_space}\")\n",
    "print(f\"action_space: {env.action_space}\")\n",
    "print(f\"action_space.sample: {env.action_space.sample()}\")\n",
    "\n",
    "n_steps = 20\n",
    "\n",
    "for step in range(n_steps):\n",
    "    obs, reward, terminated, truncated, info = env.step(action=env.action_space.sample())\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models from stable_baselines3\n",
    "\n",
    "Train with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PPO'''\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"ppo\")\n",
    "\n",
    "model_ppo = PPO(\"MultiInputPolicy\", env, verbose=0, tensorboard_log=\"logs\")\n",
    "model_ppo.learn(total_timesteps=2000000)\n",
    "model_ppo.save(\"result/rl-restrict/ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A2C'''\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"a2c\")\n",
    "\n",
    "model_a2c = A2C(\"MultiInputPolicy\", env, verbose=0)\n",
    "model_a2c.learn(total_timesteps=1000)\n",
    "model_a2c.save(\"result/rl-restrict/a2c_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DQN'''\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"dqn\")\n",
    "\n",
    "model_dqn = DQN(\"MultiInputPolicy\", env, verbose=0)\n",
    "model_dqn.learn(total_timesteps=10000)\n",
    "model_dqn.save(\"result/rl-restrict/dqn_pairtrading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model_ppo, model_a2c, model_dqn\n",
    "\n",
    "# model_ppo = PPO.load(\"result/rl-restrict/ppo_pairtrading.zip\")\n",
    "# model_a2c = A2C.load(\"result/rl-restrict/a2c_pairtrading.zip\")\n",
    "model_dqn = DQN.load(\"result/rl-restrict/dqn_pairtrading.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"ppo\", isKelly=True)\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"a2c\")\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_a2c.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Finished!\n"
     ]
    }
   ],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"dqn\")\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_dqn.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze with PyFolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ending capital of networth_a2c.csv is ['2023-10-31 23:59:59.999000', '9931.931795015245']\n",
      "The ending capital of networth_dqn.csv is ['2023-10-31 23:59:59.999000', '9940.087414121654']\n",
      "The ending capital of networth_ppo.csv is ['2023-10-31 23:59:59.999000', '9970.694830722687']\n",
      "The best model is networth_ppo.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = f\"result/rl-restrict/\"\n",
    "os.remove(f\"{folder_path}networth_test.csv\") if os.path.exists(f\"{folder_path}networth_test.csv\") else None\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "best_res, best_model = None, None\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        # Loop through the lines in the CSV file\n",
    "        last_line = None\n",
    "        for row in csv_reader:\n",
    "            last_line = row  # Update last_line with the current row\n",
    "    \n",
    "    if best_res is None or float(best_res) < float(last_line[1]):\n",
    "        best_res = last_line[1]\n",
    "        best_model = file_name\n",
    "\n",
    "    print(f\"The ending capital of {file_name} is {last_line[0:2]}\")\n",
    "\n",
    "print(f\"The best model is {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_return(networthcsv):\n",
    "    returns = pd.read_csv(networthcsv, names=['datetime', 'returns', \"action\", \"position\", \"order0\", \"order1\"])\n",
    "    returns['datetime'] = pd.to_datetime(returns['datetime'])\n",
    "    returns.set_index('datetime', inplace=True)\n",
    "    res_daily = returns.resample('D').mean()\n",
    "    res_daily['returns'] = res_daily['returns'].pct_change()\n",
    "    res_daily = res_daily.dropna()\n",
    "    return res_daily\n",
    "\n",
    "best_return = get_return(f'result/rl-restrict/{best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = pd.read_csv(f'result/rl-restrict/{best_model}', names=[\"datetime\", \"networth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(best_df['datetime'], best_df['networth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate total orders count\n",
    "# total_orders_count = best_df.shape[0]\n",
    "\n",
    "# # Calculate won orders count\n",
    "# won_orders_count = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)].shape[0]\n",
    "\n",
    "# # Calculate lost orders count\n",
    "# lost_orders_count = best_df[(best_df['order1'] == 2) & (best_df['position'] == 0)].shape[0]\n",
    "\n",
    "# # Calculate Win/Loss order ratio\n",
    "# win_loss_order_ratio = won_orders_count / lost_orders_count if lost_orders_count != 0 else np.inf\n",
    "\n",
    "# # Calculate Avg order pnl\n",
    "# avg_order_pnl = best_df['order0'].mean()\n",
    "\n",
    "# # Calculate Avg order pnl won\n",
    "# avg_order_pnl_won = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg order pnl lost\n",
    "# avg_order_pnl_lost = best_df[(best_df['order1'] == 2) & (best_df['position'] == 0)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg long order pnl\n",
    "# avg_long_order_pnl = best_df[(best_df['order1'] == 1) & (best_df['position'] == 2)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg short order pnl\n",
    "# avg_short_order_pnl = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)]['order1'].mean()\n",
    "\n",
    "# # Print the calculated indices\n",
    "# print(\"Total orders count:\", total_orders_count)\n",
    "# print(\"Won orders count:\", won_orders_count)\n",
    "# print(\"Lost orders count:\", lost_orders_count)\n",
    "# print(\"Win/Loss order ratio:\", win_loss_order_ratio)\n",
    "# print(\"Avg order pnl:\", avg_order_pnl)\n",
    "# print(\"Avg order pnl won:\", avg_order_pnl_won)\n",
    "# print(\"Avg order pnl lost:\", avg_order_pnl_lost)\n",
    "# print(\"Avg long order pnl:\", avg_long_order_pnl)\n",
    "# print(\"Avg short order pnl:\", avg_short_order_pnl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyfolio\n",
    "\n",
    "# pyfolio.tears.create_full_tear_sheet(best_return['returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
