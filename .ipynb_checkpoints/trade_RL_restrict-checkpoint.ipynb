{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a custom Environment for Pair Trading\n",
    "\n",
    "Some examples on the market\n",
    "* [custom env example](https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb#scrollTo=RqxatIwPOXe_)\n",
    "* [StockTradingEnv by Adam King](https://github.com/notadamking/Stock-Trading-Environment)\n",
    "* [FinRL](https://github.com/AI4Finance-Foundation/FinRL)\n",
    "\n",
    "Target is to construct a custom Env for pair trading\n",
    "This env restrict the behaviour of RL learner to pair trading only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gymnasium import spaces\n",
    "from datetime import date\n",
    "from envs.env_gridsearch import kellycriterion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from utils.read2df import read2df\n",
    "\n",
    "os.makedirs(\"result/rl-restrict\", exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(f\"result/rl-restrict/\"):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbols = ['BTCUSDT', 'ETHUSDT', 'LTCUSDT', 'XMRUSDT', 'BNBUSDT', 'ADAUSDT', 'DOGEUSDT', 'SOLUSDT', 'TRXUSDT']\n",
    "symbols = ['BTCUSDT', 'BTCUSD', 'BTCTUSD', 'BTCUSDC', 'BTCBUSD', 'BTCDAI']\n",
    "# symbols = ['USDCUSDT', 'DAIUSDT', 'TUSDUSDT', 'BUSDUSDT', 'USDCTUSD', 'USDCBUSD', 'DAIBUSD', 'TUSDBUSD', 'BUSDDAI']\n",
    "start_date = '2022-01-01'\n",
    "trade_date = '2023-01-01'\n",
    "\n",
    "# freqs = {'1h':60, '2h':120, '4h':240, '6h':360, '8h':480, '12h':720, '1d':1440}\n",
    "freqs = {'3m':3, '5m':5, '15m':15, '30m':30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from `binance-public-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if symbols is None:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1\n",
    "else:\n",
    "    !python binance-public-data/python/download-kline.py \\\n",
    "        -s {\" \".join(symbols)} -i {\" \".join(list(freqs.keys()))} -startDate {start_date} -t spot -skip-daily 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dfs = read2df(symbols, freqs)\n",
    "\n",
    "with open('result/cointncorr.pickle', 'rb') as pk:\n",
    "    data = pickle.load(pk)\n",
    "\n",
    "freq_position = list(freqs.keys()).index(data[1])\n",
    "\n",
    "df0 = dfs[freq_position][dfs[freq_position]['tic']==data[0][0]].reset_index(drop=True)\n",
    "df1 = dfs[freq_position][dfs[freq_position]['tic']==data[0][1]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data before `trade_data` as training data, after `trade_data` is trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = df0[df0['datetime'] < trade_date]\n",
    "train1 = df1[df1['datetime'] < trade_date]\n",
    "\n",
    "test0 = df0[df0['datetime'] >= trade_date]\n",
    "test1 = df1[df1['datetime'] >= trade_date]\n",
    "\n",
    "print(f\"The length of our training data: {len(train0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Don't use custom observation & action spaces\n",
    "See the warning on https://gymnasium.farama.org/api/spaces/\n",
    "'''\n",
    "\n",
    "# class PairTradingActionSpace(gym.Space):\n",
    "#   def __init__(self, low=-1.0, high=1.0, shape=(2, ), dtype=np.float32):\n",
    "#     super().__init__(shape, dtype)\n",
    "#     self.low = low\n",
    "#     self.high = high\n",
    "\n",
    "#   def sample(self):\n",
    "#     action = np.random.uniform(self.low, self.high, self.shape)\n",
    "#     # Normalize the action so that the summation of action[0] and action[1] is within -1 and 1.\n",
    "#     action = action / np.linalg.norm(action)\n",
    "#     return action\n",
    "\n",
    "#   def contains(self, x):\n",
    "#     return np.all(self.low <= x) and np.all(x <= self.high) and np.linalg.norm(x) <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the custom Environment\n",
    "\n",
    "The behaviour of RL learner is restricted. \n",
    "\n",
    "The action is defined as discrete actions -1, 0, 1\n",
    "\n",
    "-1 means short df0 long df1, 0 means close position, +1 means long df0 short df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lookback period for the observation space\n",
    "PERIOD = 1500 # Only look at the current price\n",
    "CASH = 10000\n",
    "isKelly = True\n",
    "\n",
    "class PairTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    # for pair trading, we need to feed in two OHLCV dataframes\n",
    "    def __init__(self, df0, df1, tc=0.001, period=PERIOD, cash=CASH, isKelly=True, model=\"\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if not df0['time'].equals(df1['time']):\n",
    "            raise ValueError(\"Two dataframe must have same time index\")\n",
    "\n",
    "        self.cash = cash\n",
    "        self.period = period\n",
    "        self.model = model\n",
    "\n",
    "        self.tic0 = df0['tic'].iloc[0]\n",
    "        self.tic1 = df1['tic'].iloc[0]\n",
    "\n",
    "        # transaction cost\n",
    "        self.tc = tc\n",
    "        self.isKelly = isKelly\n",
    "\n",
    "        self.df0 = df0[['close', 'datetime']]\n",
    "        self.df1 = df1[['close', 'datetime']]\n",
    "\n",
    "        self.reward_range = (-np.inf, np.inf)\n",
    "\n",
    "        # Baseline 3 does not support Dict/Tuple action spaces....only Box Discrete MultiDiscrete MultiBinary\n",
    "        # self.action_space = spaces.Dict({\n",
    "        #     \"isAction\": spaces.Discrete(2), # Whether we make an action or not (0 or 1)\n",
    "        #     \"amount\": spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float64)  # Long max 100% or short max 100%\n",
    "        # })\n",
    "\n",
    "        # We should only consider the current status should be `long leg df0`, `do nothing`, `long leg df1` \n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # self.observation_space = spaces.Dict({\n",
    "        #     \"Position\": spaces.Discrete(3),  # currently `long leg df0`, `hold nothing`, `long leg df1`\n",
    "        #     \"zscore\": spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float64)  # Zscore of the spread\n",
    "        # })\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float64)\n",
    "\n",
    "        # if the length is 35, then the index shall be 0~34\n",
    "        self.max_steps = len(df0)-1\n",
    "    \n",
    "    def _kellycriterion(self, direct):\n",
    "        # direct is +1 or -1\n",
    "        spreads = pd.Series(self.residuals.iloc[-self.period:-1]) * direct   \n",
    "        kc_f = kellycriterion(spreads)\n",
    "\n",
    "        return kc_f\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # The current step is always higher than the PERIOD as defined in the \n",
    "\n",
    "        model = sm.OLS(\n",
    "            df0['close'].iloc[self.current_step-self.period+1: self.current_step], \n",
    "            sm.add_constant(df1['close'].iloc[self.current_step-self.period+1: self.current_step])\n",
    "        ).fit()\n",
    "\n",
    "        # positive residual means df0 > df1 at that point\n",
    "        self.residuals = model.resid\n",
    "        zscores = self.residuals / np.std(self.residuals)\n",
    "\n",
    "        return np.array([zscores.iloc[-1]])\n",
    "\n",
    "    def _take_action(self, action):\n",
    "\n",
    "        self.curr_price0 = self.df0['close'].iloc[self.current_step]\n",
    "        self.curr_price1 = self.df1['close'].iloc[self.current_step]\n",
    "\n",
    "        self.action = action\n",
    "        \n",
    "        if self.action == 0: # The action should be 0 `long df0 short df1`, 1 `do nothing`, 2 `short df0 long df1`\n",
    "            if self.Position == 0: # Position 0 for `long leg df0` right now\n",
    "                # We shouldn't do anything because we already have a long leg df0 position\n",
    "                self.order_amount0 = 0\n",
    "                self.order_amount1 = 0\n",
    "            \n",
    "            elif self.Position  == 1: # That means we don't have any position right now\n",
    "                # evaluate purchasing power \n",
    "                max_amount0 = self.cash/self.curr_price0\n",
    "                max_amount1 = self.cash/self.curr_price1\n",
    "\n",
    "                self.order_amount0 = max_amount0 * (self._kellycriterion(direct=1) if self.isKelly else 1)\n",
    "                self.order_amount1 = -max_amount1 * (self._kellycriterion(direct=-1) if self.isKelly else 1)\n",
    "\n",
    "                self.holding0 = self.order_amount0\n",
    "                self.holding1 = self.order_amount1\n",
    "\n",
    "                # Open a new position\n",
    "                self.cash -= (\n",
    "                    self.order_amount0*self.curr_price0 + self.order_amount1*self.curr_price1 \n",
    "                    + (np.abs(self.order_amount0*self.curr_price0)+np.abs(self.order_amount1*self.curr_price1))*self.tc\n",
    "                )\n",
    "                self.Position = 0\n",
    "            \n",
    "            elif self.Position == 2: # We have long leg df1 right now\n",
    "                # Then we should close our position\n",
    "\n",
    "                self.order_amount0 = self.holding0\n",
    "                self.order_amount1 = self.holding1\n",
    "\n",
    "                self.cash += (\n",
    "                    self.order_amount0*self.curr_price0 + self.order_amount1*self.curr_price1 \n",
    "                    - (np.abs(self.order_amount0*self.curr_price0)+np.abs(self.order_amount1*self.curr_price1))*self.tc\n",
    "                )\n",
    "                self.holding0 = 0\n",
    "                self.holding1 = 0\n",
    "                self.Position = 1\n",
    "\n",
    "        elif action == 1:\n",
    "            # Because we should do nothing\n",
    "            self.order_amount0 = 0\n",
    "            self.order_amount1 = 0\n",
    "    \n",
    "        elif action == 2: # we should short df0 long df1\n",
    "            if self.Position == 0: # if we already have a long df0 short df 1 position\n",
    "                # Close the position\n",
    "                self.order_amount0 = self.holding0\n",
    "                self.order_amount1 = self.holding1\n",
    "\n",
    "                self.cash += (\n",
    "                    self.holding0*self.curr_price0 + self.holding1*self.curr_price1 \n",
    "                    - (np.abs(self.holding0*self.curr_price0)+np.abs(self.holding1*self.curr_price1))*self.tc\n",
    "                )\n",
    "                self.holding0 = 0\n",
    "                self.holding1 = 0\n",
    "                self.Position = 1\n",
    "\n",
    "            elif self.Position == 1:\n",
    "                # Open a new position\n",
    "                max_amount0 = self.cash/self.curr_price0\n",
    "                max_amount1 = self.cash/self.curr_price1\n",
    "\n",
    "                self.order_amount0 = -max_amount0 * (self._kellycriterion(direct=1) if self.isKelly else 1)\n",
    "                self.order_amount1 = max_amount1 * (self._kellycriterion(direct=-1) if self.isKelly else 1)\n",
    "\n",
    "                self.holding0 = self.order_amount0\n",
    "                self.holding1 = self.order_amount1\n",
    "\n",
    "                # Open a new position\n",
    "                self.cash -= (\n",
    "                    self.holding0*self.curr_price0 + self.holding1*self.curr_price1\n",
    "                    + (np.abs(self.holding0*self.curr_price0)+np.abs(self.holding1*self.curr_price1))*self.tc\n",
    "                )\n",
    "\n",
    "                self.Position = 2\n",
    "            \n",
    "            elif self.Position == 2:\n",
    "                # We should do nothing\n",
    "                self.order_amount0 = 0\n",
    "                self.order_amount1 = 0\n",
    "\n",
    "        # We record the net_worth from previous period to prev_net_worth\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.cash + self.holding0*self.curr_price0 + self.holding1*self.curr_price1\n",
    "\n",
    "    def step(self, action):\n",
    "        self.action = action # for rendering\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "\n",
    "        self.observation = self._next_observation()\n",
    "        reward = self.net_worth - self.prev_net_worth\n",
    "        terminated = bool(self.current_step >= self.max_steps)\n",
    "        truncated = bool(self.net_worth <= 0)\n",
    "        info = {}\n",
    "\n",
    "        return self.observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.cash = self.cash\n",
    "        self.net_worth = self.cash\n",
    "        self.prev_net_worth = self.cash\n",
    "        self.max_net_worth = self.cash\n",
    "        self.Position = 0\n",
    "        self.holding0 = 0\n",
    "        self.holding1 = 0\n",
    "        self.render_step = 0\n",
    "        self.order_amount0 = 0\n",
    "        self.order_amount1 = 0\n",
    "\n",
    "        self.current_step = self.period # np.random.randint(self.period, self.max_steps)\n",
    "\n",
    "        return self._next_observation(), {}\n",
    "    \n",
    "    def render(self):\n",
    "        profit = self.net_worth - self.cash\n",
    "        # print(self.df0['datetime'].iloc[self.current_step], self.net_worth)\n",
    "\n",
    "        with open(f\"result/rl-restrict/networth_{self.model}.csv\", mode='a', newline='') as csv_f:\n",
    "            if self.action != 1:\n",
    "                writer = csv.writer(csv_f)\n",
    "                writer.writerow(\n",
    "                    [self.df0['datetime'].iloc[self.current_step], \n",
    "                    self.net_worth, self.action, self.Position, \n",
    "                    self.curr_price0*self.order_amount0, self.curr_price1*self.order_amount1]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with baselin3 `env_checker`\n",
    "\n",
    "Check if the env meets the requirements of `stable_baseline3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "# > UserWarning: The action space is not based off a numpy array. Typically this means it's either a Dict or Tuple space. This type of action space is currently not supported by Stable Baselines 3. You should try to flatten the action using a wrapper.\n",
    "# Baseline 3 does not support Dict/Tuple action spaces....only Box Discrete MultiDiscrete MultiBinary\n",
    "# Is there another way to achieve the same functionality?\n",
    "\n",
    "env = PairTradingEnv(train0, train1)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a test run with random generated actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PairTradingEnv(train0, train1, tc=0, model=\"test\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "print(f\"observation_space: {env.observation_space}\")\n",
    "print(f\"action_space: {env.action_space}\")\n",
    "print(f\"action_space.sample: {env.action_space.sample()}\")\n",
    "\n",
    "n_steps = 5\n",
    "\n",
    "for step in range(n_steps):\n",
    "    obs, reward, terminated, truncated, info = env.step(action=env.action_space.sample())\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models from stable_baselines3\n",
    "\n",
    "Train with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PPO'''\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"ppo\", isKelly=False)\n",
    "\n",
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"logs\")\n",
    "model_ppo.learn(total_timesteps=100000)\n",
    "model_ppo.save(\"result/rl-restrict/ppo_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A2C'''\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"a2c\", isKelly=False)\n",
    "\n",
    "model_a2c = A2C(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"logs\")\n",
    "model_a2c.learn(total_timesteps=100000)\n",
    "model_a2c.save(\"result/rl-restrict/a2c_pairtrading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DQN'''\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "env = PairTradingEnv(train0, train1, tc=0, model=\"dqn\", isKelly=False)\n",
    "\n",
    "model_dqn = DQN(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"logs\")\n",
    "model_dqn.learn(total_timesteps=100000)\n",
    "model_dqn.save(\"result/rl-restrict/dqn_pairtrading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model_ppo, model_a2c, model_dqn\n",
    "\n",
    "model_ppo = PPO.load(\"result/rl-restrict/ppo_pairtrading.zip\")\n",
    "model_a2c = A2C.load(\"result/rl-restrict/a2c_pairtrading.zip\")\n",
    "model_dqn = DQN.load(\"result/rl-restrict/dqn_pairtrading.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"ppo\")\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_ppo.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"a2c\")\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_a2c.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PairTradingEnv(test0, test1, tc=0, model=\"dqn\")\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action, _states = model_dqn.predict(obs)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "    if terminated:\n",
    "        print(\"Test Finished!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"bankrupted!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze with PyFolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"result/rl-restrict/\"\n",
    "os.remove(f\"{folder_path}networth_test.csv\") if os.path.exists(f\"{folder_path}networth_test.csv\") else None\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "best_res, best_model = None, None\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        # Loop through the lines in the CSV file\n",
    "        last_line = None\n",
    "        for row in csv_reader:\n",
    "            last_line = row  # Update last_line with the current row\n",
    "    \n",
    "    if best_res is None or float(best_res) < float(last_line[1]):\n",
    "        best_res = last_line[1]\n",
    "        best_model = file_name\n",
    "\n",
    "    print(f\"The ending capital of {file_name} is {last_line[0:1]}\")\n",
    "\n",
    "print(f\"The best model is {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_return(networthcsv):\n",
    "    returns = pd.read_csv(networthcsv, names=['datetime', 'returns', \"action\", \"position\", \"order0\", \"order1\"])\n",
    "    returns['datetime'] = pd.to_datetime(returns['datetime'])\n",
    "    returns.set_index('datetime', inplace=True)\n",
    "    res_daily = returns.resample('D').mean()\n",
    "    res_daily['returns'] = res_daily['returns'].pct_change()\n",
    "    res_daily = res_daily.dropna()\n",
    "    return res_daily\n",
    "\n",
    "best_return = get_return(f'result/rl-restrict/{best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = pd.read_csv(f'result/rl-restrict/{best_model}', names=[\"datetime\", \"networth\", \"action\", \"position\", \"order0\", \"order1\"])\n",
    "best_df = best_df[best_df['action']!=1]\n",
    "best_df = best_df[best_df['order0']!=0]\n",
    "best_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate total orders count\n",
    "# total_orders_count = best_df.shape[0]\n",
    "\n",
    "# # Calculate won orders count\n",
    "# won_orders_count = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)].shape[0]\n",
    "\n",
    "# # Calculate lost orders count\n",
    "# lost_orders_count = best_df[(best_df['order1'] == 2) & (best_df['position'] == 0)].shape[0]\n",
    "\n",
    "# # Calculate Win/Loss order ratio\n",
    "# win_loss_order_ratio = won_orders_count / lost_orders_count if lost_orders_count != 0 else np.inf\n",
    "\n",
    "# # Calculate Avg order pnl\n",
    "# avg_order_pnl = best_df['order0'].mean()\n",
    "\n",
    "# # Calculate Avg order pnl won\n",
    "# avg_order_pnl_won = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg order pnl lost\n",
    "# avg_order_pnl_lost = best_df[(best_df['order1'] == 2) & (best_df['position'] == 0)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg long order pnl\n",
    "# avg_long_order_pnl = best_df[(best_df['order1'] == 1) & (best_df['position'] == 2)]['order0'].mean()\n",
    "\n",
    "# # Calculate Avg short order pnl\n",
    "# avg_short_order_pnl = best_df[(best_df['order1'] == 1) & (best_df['position'] == 0)]['order1'].mean()\n",
    "\n",
    "# # Print the calculated indices\n",
    "# print(\"Total orders count:\", total_orders_count)\n",
    "# print(\"Won orders count:\", won_orders_count)\n",
    "# print(\"Lost orders count:\", lost_orders_count)\n",
    "# print(\"Win/Loss order ratio:\", win_loss_order_ratio)\n",
    "# print(\"Avg order pnl:\", avg_order_pnl)\n",
    "# print(\"Avg order pnl won:\", avg_order_pnl_won)\n",
    "# print(\"Avg order pnl lost:\", avg_order_pnl_lost)\n",
    "# print(\"Avg long order pnl:\", avg_long_order_pnl)\n",
    "# print(\"Avg short order pnl:\", avg_short_order_pnl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "\n",
    "pyfolio.tears.create_full_tear_sheet(best_return['returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
